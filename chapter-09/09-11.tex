\section{Practical Workflow and Software}
\label{sec:adv-matrix-workflow}

This section provides a complete practical workflow for implementing the advanced matrix and tensor methods from this chapter. For detailed method comparisons, see Section~\ref{sec:adv-matrix-connections}; for diagnostics, see Section~\ref{sec:adv-matrix-diagnostics}; for marketing applications, see Section~\ref{sec:adv-matrix-applications}.

\begin{tcolorbox}[title=Box 9.1: Advanced Matrix/Tensor Workflow, colback=green!5!white, colframe=green!50!black, fonttitle=\bfseries]

\begin{quote}
Start by selecting the method—standard MC, tensor, robust, or covariate-assisted—based on the data structure (2D, 3D+, outliers, rich covariates). Then, clearly separate observed outcomes from those to be imputed under counterfactual treatment paths.

Next, tune the rank and regularisation parameters using cross-validation on held-out untreated data, reporting the chosen parameters and validation performance. Perform outlier and stability checks: if using robust methods, inspect the sparse outlier matrix; for all methods, run placebo-in-time tests.

Finally, estimate the effects by imputing counterfactuals and computing the ATT, reporting any heterogeneity. Follow the protocols in Chapter~\ref{ch:design-diagnostics} for diagnostics and Chapter~\ref{ch:inference} for valid uncertainty estimates that account for panel dependence.
\end{quote}
\end{tcolorbox}

\subsection*{Decision Tree for Method Selection}

Which advanced method should you use? The choice depends on data characteristics, research questions, and computational constraints. For a summary table, see Section~\ref{sec:adv-matrix-connections}.

\begin{enumerate}
\item \textbf{Data structure:} If data are naturally multi-way (products $\times$ stores $\times$ time), use tensor completion (Section~\ref{sec:tensor-completion}). For two-way data, use matrix completion.

\item \textbf{Data quality:} If outliers are present (stockouts, data errors), use robust MC (Section~\ref{sec:robust-matrix}). For clean data, use standard MC.

\item \textbf{Covariates:} If rich side information is available (demographics, weather), use covariate-assisted MC (Section~\ref{sec:matrix-side-info}). With minimal covariates, use standard MC.

\item \textbf{Stationarity:} If structural breaks or algorithm changes are present, use time-varying rank models (Section~\ref{sec:time-varying-rank}). For stable factor structures, use standard MC.

\item \textbf{Uncertainty quantification:} If posterior distributions and credible intervals are needed, use Bayesian MC (Section~\ref{sec:bayesian-matrix}). If point estimates suffice, use frequentist MC.

\item \textbf{Computational constraints:} For very large panels ($>$10M cells), use efficient algorithms such as Soft-Impute or SGD (Section~\ref{sec:computation}). For moderate panels, use standard algorithms (ALS, nuclear norm).
\end{enumerate}

\subsection*{Step-by-Step Implementation Guide}

\paragraph{Step 1: Prepare the data.} Organise outcomes into a matrix or tensor, then code treatment indicators (1 for treated, 0 for untreated). Collect covariates including unit characteristics and time-varying variables. Check for missing data and outliers, and visualise data using heatmaps and time series plots to understand patterns.

\paragraph{Step 2: Select the method.}
Use the decision tree above. If unsure, start with standard matrix completion as a baseline, then try advanced methods and compare.

\paragraph{Step 3: Choose tuning parameters.} Select rank $R$ using cross-validation, information criteria, or eigenvalue ratio test (Section~\ref{sec:adv-matrix-diagnostics}). Select regularisation parameters ($\eta$, $\lambda$, $\gamma$) using cross-validation. For Bayesian methods, choose priors based on domain knowledge or use weakly informative priors.

\paragraph{Step 4: Estimate the model.} Run the chosen algorithm (ALS, ADMM, Soft-Impute, MCMC) and check convergence by plotting the objective function and comparing multiple initialisations. Compute imputed counterfactuals for treated cells, then calculate treatment effects as observed minus imputed.

\paragraph{Step 5: Conduct diagnostics.} Follow the diagnostic checklist in Section~\ref{sec:adv-matrix-diagnostics}. Assess rank selection using scree plots and stability across subsamples. Perform outlier detection using residual plots and robust versus non-robust comparison. Evaluate covariate relevance through variable importance and partial dependence. Validate computation by checking convergence and solution stability.

\paragraph{Step 6: Perform inference.} Compute standard errors using bootstrap, asymptotic theory, or posterior distributions. Construct confidence intervals or credible intervals. Conduct placebo tests by treating random pre-treatment cells as missing. Report treatment effects with uncertainty quantification.

\paragraph{Step 7: Report results.} Present treatment effect estimates with confidence intervals and discuss heterogeneity across units, time, and subgroups. Compare to alternative methods such as SC and DiD. Discuss limitations including assumptions and sensitivity to tuning. Provide replication materials including data, code, and documentation.


\subsection*{Software Recommendations}

For detailed algorithm comparisons and benchmarks, see Section~\ref{sec:computation}.

\begin{table}[htbp]
\begin{tighttable}
\centering
\caption{Software Packages by Task and Language}
\label{tab:software-summary}
\begin{tabularx}{\textwidth}{Y Y Y Y}
\toprule
\textbf{Task} & \textbf{R} & \textbf{Python} & \textbf{Julia} \\
\midrule
Standard MC & \texttt{softImpute} & \texttt{fancyimpute} & \texttt{LowRankModels.jl} \\
\addlinespace
Tensor decomposition & \texttt{rTensor} & \texttt{tensorly} & \texttt{TensorToolbox.jl} \\
\addlinespace
Robust PCA & \texttt{MASS} & \texttt{sklearn.decomposition} & — \\
\addlinespace
Bayesian inference & \texttt{rstan}, \texttt{JAGS} & \texttt{pymc}, \texttt{numpyro} & \texttt{Turing.jl} \\
\bottomrule
\end{tabularx}
\end{tighttable}
\end{table}

\paragraph{Package recommendations by use case.} For sparse matrices, \texttt{softImpute} (R) is fastest. For tensors, \texttt{tensorly} (Python) offers the most flexibility. For Bayesian inference, \texttt{pymc} (Python) is most user-friendly. For the most general approach, \texttt{LowRankModels.jl} (Julia) handles arbitrary loss functions and regularisers.

\subsection*{Common Pitfalls and Solutions}

\begin{table}[htbp]
\begin{tighttable}
\centering
\caption{Common Pitfalls and Solutions}
\label{tab:pitfalls}
\begin{tabularx}{\textwidth}{Y Y Y}
\toprule
\textbf{Pitfall} & \textbf{Symptom} & \textbf{Solution} \\
\midrule
Overfitting & Poor out-of-sample $R^2$; rank too large & Cross-validation; prefer smaller ranks; regularise aggressively \\
\addlinespace
Computational bottleneck & Algorithm too slow for panel size & Soft-Impute, SGD; exploit sparsity; distributed computing \\
\addlinespace
Interpretation challenges & Factors lack meaning & Plot loadings; relate to domain; use rotation (varimax) \\
\addlinespace
Parameter sensitivity & Results change with tuning & Report multiple specifications; sensitivity analysis; data-driven selection \\
\bottomrule
\end{tabularx}
\end{tighttable}
\end{table}

\paragraph{Overfitting in high dimensions.}
When the rank is too large, the model fits noise. In Case Study 1 (Section~\ref{sec:adv-matrix-applications}), cross-validation selected $R = 10$ over larger alternatives. Solution: prefer parsimony; regularise with large $\eta$.

\paragraph{Computational bottlenecks.}
Large panels require efficient algorithms. In Case Study 2, the 800 $\times$ 150 $\times$ 104 panel (12M cells) used ADMM with sparse operations. Solution: see algorithm comparison in Section~\ref{sec:computation}.

\paragraph{Interpretation challenges.}
Many factors can be hard to interpret. In Case Study 3, factor loadings were related to market demographics. Solution: plot loadings over time; use rotation methods; report interpretations.

\paragraph{Sensitivity to tuning parameters.}
Results may depend on rank and regularisation. In Case Study 2, sensitivity analysis showed estimates stable for $\lambda \in [0.10, 0.20]$. Solution: report results for multiple tuning parameters; use data-driven selection.
