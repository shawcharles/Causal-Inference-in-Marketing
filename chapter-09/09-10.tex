\section{Marketing Applications}
\label{sec:adv-matrix-applications}

This section demonstrates the advanced matrix and tensor methods from this chapter through four marketing case studies. Table~\ref{tab:case-summary} summarises the applications.

\begin{table}[htbp]
\begin{tighttable}
\centering
\caption{Summary of Marketing Applications}
\label{tab:case-summary}
\begin{tabularx}{\textwidth}{Y Y Y Y Y}
\toprule
\textbf{Case} & \textbf{Method} & \textbf{Data Structure} & \textbf{Challenge} & \textbf{Key Finding} \\
\midrule
E-Commerce & Tensor Completion & Users $\times$ Items $\times$ Context & Multi-way structure & +8\% CTR, +5\% purchase \\
\addlinespace
Retail Stockouts & Robust MC & Products $\times$ Store-weeks & Outliers (stockouts) & +18\% sales (vs 12\% standard) \\
\addlinespace
Product Launch & Covariate-Assisted TC & Products $\times$ Markets $\times$ Weeks & Market heterogeneity & +22\% sales, heterogeneity \\
\addlinespace
Advertising & Time-Varying + Bayesian & Platforms $\times$ Creatives $\times$ Weeks & Algorithm changes & +15\% CTR with CIs \\
\bottomrule
\end{tabularx}
\end{tighttable}
\end{table}

\subsection*{Case Study 1: E-Commerce Recommendation Systems}

\textbf{Method:} Tensor completion (Section~\ref{sec:tensor-completion}).

An e-commerce platform observes user engagement (clicks, add-to-cart, purchases) for 50,000 users, 10,000 items, and 5 contexts (mobile, desktop, tablet, morning, evening). The data form a three-way tensor: users $\times$ items $\times$ contexts. The platform launches a new recommendation algorithm for 10,000 users in the mobile context for 4 weeks.

\paragraph{Estimation.} Tensor completion imputes counterfactual engagement for treated users in the mobile context. We estimate a CP decomposition with rank $R = 10$ using ALS (Section~\ref{sec:computation}). The first factor captures user preferences (electronics vs fashion). The second factor captures item popularity. The third factor captures context effects (mobile users browse more but buy less). The remaining factors capture interactions.

\paragraph{Results.}
\begin{itemize}
\item \textbf{Click-through rate:} +8\% (95\% CI: [5\%, 11\%]).
\item \textbf{Purchase rate:} +5\% (95\% CI: [2\%, 8\%]).
\item \textbf{Heterogeneity:} Power users: +12\%; casual users: +4\%.
\end{itemize}
Tensor completion reveals heterogeneity by leveraging the multi-way structure.

\paragraph{Diagnostics.} Cross-validation on held-out pre-treatment cells achieves $R^2 = 0.72$. Placebo tests (treating random pre-treatment cells as missing) produce near-zero effects (mean 0.01, SE 0.3). The tensor completion is valid (Section~\ref{sec:adv-matrix-diagnostics}).

\subsection*{Case Study 2: Retail Chain with Stockouts}

\textbf{Method:} Robust matrix completion (Section~\ref{sec:robust-matrix}).

A grocery retailer with 800 products across 150 stores over 104 weeks experiences frequent stockouts (8\% of cells). A new inventory management system is implemented in 30 stores for 12 weeks. The goal is to estimate the causal effect on sales.

\paragraph{Estimation.} Robust matrix completion separates stockouts from underlying demand. We solve SPCP with $\lambda = 0.15$ (chosen by cross-validation). The low-rank component $\hat{\mathbf{L}}$ captures demand. The sparse component $\hat{\mathbf{S}}$ captures stockouts (95\% of non-zero entries in $\hat{\mathbf{S}}$ are negative).

\paragraph{Results.}
\begin{itemize}
\item \textbf{Robust MC ATT:} +18\% sales (95\% CI: [14\%, 22\%]).
\item \textbf{Standard MC ATT:} +12\% (biased downward by stockouts).
\item \textbf{Stockout reduction:} 60\% decrease (from 8\% to 3\% of cells).
\end{itemize}
The robust correction accounts for 6 percentage points of the treatment effect. Half of the sales increase reflects higher demand due to improved product availability.

\paragraph{Diagnostics.} Residual analysis confirms heavy-tailed distribution before robust correction; approximately Gaussian after. Sensitivity to $\lambda$: estimates stable for $\lambda \in [0.10, 0.20]$.

\subsection*{Case Study 3: Multi-Market Product Launch}

\textbf{Method:} Covariate-assisted tensor completion (Section~\ref{sec:matrix-side-info}).

A consumer packaged goods company launches 40 new products across 25 markets over 52 weeks. Products are launched at different times in different markets (staggered rollout). Markets vary in size, demographics, and competitive intensity.

\paragraph{Estimation.} Covariate-assisted tensor completion incorporates market characteristics. We estimate a CP decomposition with rank $R = 6$ on residuals after controlling for market size, demographics, and competitive intensity. The covariates explain 50\% of the variation in sales. The tensor decomposition captures residual co-movement.

\paragraph{Results.}
\begin{itemize}
\item \textbf{Overall ATT:} +22\% sales (95\% CI: [18\%, 26\%]).
\item \textbf{By market size:} Large: +28\%; Small: +16\%.
\item \textbf{By income:} High: +25\%; Low: +18\%.
\item \textbf{Dynamic pattern:} Week 4: +15\%; Week 12: +25\% (growing awareness).
\end{itemize}
Covariate-assisted tensor completion reveals heterogeneity by leveraging market characteristics. The time mode captures the dynamic pattern.

\paragraph{Diagnostics.} First-step $R^2 = 0.50$. Out-of-sample $R^2$ (tensor completion on residuals): 0.68. Sensitivity to covariate specification: estimates stable across specifications.

\subsection*{Case Study 4: Advertising Across Platforms}

\textbf{Methods:} Time-varying rank (Section~\ref{sec:time-varying-rank}) and Bayesian hierarchical (Section~\ref{sec:bayesian-matrix}).

An advertiser runs campaigns across 4 platforms (search, social, display, video) using 20 creatives over 26 weeks. The data form a three-way tensor: platforms $\times$ creatives $\times$ weeks. A new bidding strategy is implemented for 2 platforms (search and social) for 8 weeks.

\paragraph{Estimation.} Time-varying rank models adapt to platform algorithm changes. In week 12, the social platform changes its algorithm, introducing a new factor (video content prioritised). We estimate $R_t = 4$ before week 12 and $R_t = 5$ after week 12.

Bayesian hierarchical tensor completion shares information across platforms. We place a hierarchical prior on platform-level factors, shrinking them toward a population-level factor. This improves estimates for platforms with limited data (video has fewer observations than search).

\paragraph{Results.}
\begin{itemize}
\item \textbf{Overall CTR:} +15\% (95\% CI: [12\%, 18\%]).
\item \textbf{Overall conversion:} +10\% (95\% CI: [7\%, 13\%]).
\item \textbf{Search:} +18\% CTR (95\% CI: [14\%, 22\%]).
\item \textbf{Social:} +12\% CTR (95\% CI: [8\%, 16\%]).
\end{itemize}
Posterior credible intervals quantify uncertainty. The hierarchical model reduces standard errors for video by 25\% by borrowing strength from other platforms.

\paragraph{Diagnostics.} Change-point detection identifies week 12 as a structural break. Model comparison: Bayes factor for time-varying vs static model = 18 (strong evidence for time-varying).

\subsection*{Lessons Learned}

\begin{tcolorbox}[colback=blue!5!white,colframe=blue!50!black,title=Key Takeaways from Marketing Applications]

\paragraph{1. Match method to data structure:}
\begin{itemize}
\item Multi-way structure (user $\times$ item $\times$ context) $\rightarrow$ Tensor completion.
\item Outliers/stockouts $\rightarrow$ Robust MC.
\item Rich covariates $\rightarrow$ Covariate-assisted methods.
\item Structural breaks $\rightarrow$ Time-varying models.
\end{itemize}

\paragraph{2. Heterogeneity is the norm:}
\begin{itemize}
\item Treatment effects vary by user segment, market, platform.
\item Advanced methods reveal heterogeneity that standard methods mask.
\item Report subgroup effects alongside overall ATT.
\end{itemize}

\paragraph{3. Diagnostics are essential:}
\begin{itemize}
\item Cross-validation validates the imputation model.
\item Placebo tests assess pre-treatment fit.
\item Sensitivity analyses assess robustness to specification choices.
\end{itemize}

\paragraph{4. Quantify uncertainty:}
\begin{itemize}
\item Report confidence/credible intervals, not just point estimates.
\item Bayesian methods provide natural uncertainty quantification.
\item Bootstrap provides frequentist CIs for non-Bayesian methods.
\end{itemize}

\paragraph{5. Robust methods matter:}
\begin{itemize}
\item Stockouts, data errors, and outliers are common in marketing data.
\item Robust MC can change treatment effect estimates by 50\% (Case 2: 18\% vs 12\%).
\item Always compare robust and standard estimates.
\end{itemize}
\end{tcolorbox}
