\section{The Causal Revolution in Marketing}
\label{sec:causal-revolution}

Marketing is shifting from metrics-focused dashboards to mechanism-focused causal analysis. For much of the digital era, organisations measured success using intermediate metrics---impressions, clicks, page views, ad recall---that serve as proxies for business outcomes. These metrics help optimise within a fixed strategic framework: if clicks predict sales, we can tune bidding to maximise clicks per dollar. But when used to assess strategic changes, intermediate metrics mislead. A campaign generating many clicks may not drive incremental sales if those clicks come from users who would have bought anyway. A loyalty programme that raises repeat purchase rates may not increase profits if it merely shifts purchases forward in time rather than expanding total consumption.

The incrementality problem has prompted major platforms to build causal measurement tools. Meta's Conversion Lift uses an intent-to-treat design: users are randomly assigned to a holdout group, blocked from seeing the campaign's ads, or to a treatment group eligible for delivery. Conversion rates are compared to estimate incremental lift. Within the treatment group, however, the platform's targeting algorithm still determines who actually sees ads---randomisation occurs at the eligibility level, not exposure level. Google's Geo-Experiments randomly vary advertising intensity across geographic areas to estimate aggregate regional effects. Amazon's Brand Lift studies use similar holdout designs for awareness and intent. These tools represent genuine advances over last-touch attribution, but they share common limitations: proprietary implementations that researchers cannot audit, aggregated outputs that obscure heterogeneity and dynamics, and platform-specific designs that prevent cross-channel comparison. \cite{lewis2015unfavorable} quantify a related problem: even well-designed digital experiments often lack statistical power to detect economically meaningful effects, because per-user revenue variance swamps treatment effects.

Panel data methods supplement platform tools by offering transparent, reproducible, and flexible approaches to causal inference. The methods in this book apply to any panel dataset, not just those accessible via platform interfaces. They incorporate external data---competitor actions, macroeconomic conditions, offline behaviour---that platforms do not observe. They estimate long-run effects by tracking outcomes over months or years rather than the weeks typical of platform experiments. Spillovers, dynamics, and heterogeneity can be modelled explicitly and diagnosed rigorously. Assumptions are stated, tested, and debated rather than hidden inside proprietary code.

This shift toward causal rigour reflects a broader intellectual movement. \cite{angrist2010credibility} labelled it the credibility revolution: economists began emphasising research designs that approximate randomised experiments---instrumental variables exploiting exogenous shocks, regression discontinuity designs using threshold-based assignment, and difference-in-differences comparing treated and control units before and after intervention. Combined with richer administrative data, these methods raised the evidential bar. Cross-sectional regressions with long covariate lists gave way to designs grounded in institutional detail, policy discontinuities, and natural experiments that generate credible counterfactuals.

Marketing scholarship has adopted these lessons more slowly than labour economics or public finance, but the trajectory is clear. Leading journals now routinely publish quasi-experimental studies, and methodological sophistication in causal inference is increasingly expected. This book accelerates adoption by providing a rigorous yet accessible treatment tailored to marketing's distinctive data structures and substantive questions.

The challenges ahead are formidable. Platform algorithms now decide which users see which ads, which products rank in search, and what prices appear to different customers. This algorithmic intermediation creates confounding by design: exposures depend on predicted responses, rankings on past clicks, prices on inferred willingness to pay. Causal inference must confront data-generating processes in which treatments are functions of predicted outcomes.

Privacy constraints compound the difficulty. Deprecation of third-party cookies, Apple's App Tracking Transparency, and GDPR limit cross-device and cross-platform tracking, producing missing data and measurement error. Panel methods must adapt: aggregate or differentially private data, partial identification under incomplete information, and triangulation across imperfect sources all become necessary.

Nonstationarity poses a third challenge. Consumer preferences shift, technologies emerge, competitors enter and exit, macroeconomic shocks disrupt demand. Panel methods often assume some stationarity---parallel trends, time-invariant effects, stable factor loadings---that may fail during upheaval. Methods for structural breaks, time-varying parameters, and regime changes remain active research frontiers.

Interference grows more complex in networked platforms where users connect to many others, and in competitive markets where firms react strategically in real time. Partial interference assumptions---spillovers only within clusters, decay with geographic distance---may prove inadequate for modern marketing ecosystems. Developing tractable yet realistic interference models is an open problem.

These challenges, however, create opportunities. The same platforms that complicate inference through algorithmic targeting generate unprecedented granular data: clickstreams, location traces, social graphs, review text. Computational advances permit estimation of complex models at scale. Machine learning contributes not through prediction per se, but through flexible estimation of nuisance functions---propensity scores, outcome models, latent factors---that sharpen causal estimates. Double machine learning \citep{chernozhukov2018double} and causal forests \citep{wager2018estimation} exemplify this integration, using regularised learners to handle high-dimensional confounding while preserving valid inference on treatment effects.

The methods developed in this book help readers navigate this landscape. Whether evaluating a loyalty programme, measuring advertising effectiveness, quantifying competitive dynamics, or assessing platform design changes, causal panel methods provide a disciplined framework for moving from correlation to cause. Causal claims remain provisional---grounded in approximations, not certainties. But with rigorous methods, transparent diagnostics, and systematic sensitivity analysis, we can distinguish interpretations that deserve credibility from those that do not.

\begin{table}[htbp]
\begin{tighttable}
\centering
\caption{Overview of Three Motivating Examples}
\label{tab:motivating-examples}
\begin{tabularx}{\textwidth}{Y Y Y Y}
\toprule
\textbf{Example} & \textbf{Challenges} & \textbf{Methods} & \textbf{Key Insights} \\
\midrule
Loyalty Programme Rollout & Selection bias, spillovers, dynamics, heterogeneity & Staggered DiD (Ch \ref{ch:did}), event studies (Ch \ref{ch:event}), spillover models (Ch \ref{ch:spillovers}), causal forests (Ch \ref{ch:ml-nuisance}) & 8\% avg effect, growing over time; spillovers +2\%; heterogeneous (12\% high-income, 0\% saturated markets) \\
\addlinespace
TV Advertising Carryover & Endogeneity, carryover, mediation, seasonality & Synthetic control (Ch \ref{ch:sc}), distributed lags (Ch \ref{ch:dynamics}), lasso (Ch \ref{ch:high-dim}), robust inference (Ch \ref{ch:inference}) & 5\% immediate effect, 3-week half-life; 40\% mediated via search; competitor response -20\% \\
\addlinespace
Platform Entry & Unique units, staggered timing, competition, general equilibrium & SC (Ch \ref{ch:sc}), SDID (Ch \ref{ch:generalized-sc}), factor models (Ch \ref{ch:factor}), spillover models (Ch \ref{ch:spillovers}) & 15\% avg effect; 25\% for small restaurants, 5\% chains; competitive response -30\%; category expansion (positive-sum) \\
\bottomrule
\end{tabularx}
\end{tighttable}
\end{table}
