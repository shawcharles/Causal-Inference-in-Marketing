\section{The Two Cultures of Marketing Analytics}
\label{sec:two-cultures}

In a celebrated paper, statistician Leo Breiman distinguished two cultures in statistical modelling. The first, ``data modelling'', builds explicit probabilistic models and estimates parameters under strong assumptions about functional form. The second, ``algorithmic modelling'', treats the underlying mechanism as unknown and focuses on predictive accuracy through flexible, data-adaptive algorithms. Breiman argued that statistics had long overemphasised the first culture and neglected the second, missing opportunities to harness the power of machine learning for prediction.

This dichotomy, while influential, has been critiqued as overly stark. As Andrew Gelman and others have argued, good statistical practice has always blended elements of both cultures. Data modellers routinely check their models' predictive performance through cross-validation and other checks. Algorithmic modellers increasingly seek interpretability through tools like SHAP values and partial dependence plots. The real tension is not between prediction and understanding, but between strong parametric assumptions and flexible, data-adaptive methods. Crucially, neither culture, as originally framed, directly addresses the central challenge of marketing analytics: moving from prediction or association to *causal* inference.

Marketing analytics today reflects this tension. The rise of digital platforms has fuelled an explosion in predictive modelling -- churn prediction, recommendation engines, bid optimisation. These models excel at forecasting outcomes *within* the existing system. Yet when organisations face strategic decisions -- should we launch this loyalty programme? will this price change increase long-run revenue? -- prediction alone is insufficient. We need causal inference. This is where panel data methods, grounded in quasi-experimental design but augmented with modern machine learning, offer a path forward.

Modern panel data methods for causal inference represent a synthesis -- or perhaps a third culture. They borrow the flexibility of algorithmic modelling to handle high-dimensional confounders and estimate heterogeneous treatment effects. Yet they retain the discipline of data modelling by making explicit assumptions about the causal structure, such as parallel trends or unconfoundedness, and subjecting those assumptions to diagnostic tests. Methods like Double Machine Learning epitomise this synthesis. Machine learning algorithms estimate nuisance functions with minimal parametric assumptions, while design-based identification strategies ensure that the final causal estimate is robust. This approach prioritises causal validity over pure predictive accuracy, but it uses the tools of both cultures to achieve it.

Our approach to reasoning through models is pragmatic. We do not seek a single, true model that perfectly captures the data-generating process -- such a model does not exist, and even if it did, we could not be certain we had found it. Instead, we embrace a workflow that combines four elements. We begin by articulating the identification assumptions -- parallel trends, conditional independence, factor structure, no spillovers -- required for a causal interpretation of our estimates. We then apply an estimator that implements the identification strategy, whether it be difference-in-differences, synthetic control, interactive fixed effects, or a doubly robust machine learning method. Having obtained estimates, we conduct an extensive battery of diagnostics -- pre-trend tests, placebo tests, balance checks, leave-one-out robustness, covariate balance, specification curves -- to assess whether the assumptions are plausible and whether the results are sensitive to modelling choices. Finally, we quantify through sensitivity analysis how large a violation of the key assumptions would need to be to overturn our conclusions, acknowledging that assumptions are approximations rather than exact truths. This workflow embodies the synthesis of cultures: flexible tools deployed within a disciplined causal framework.
