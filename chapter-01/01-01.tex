\section{The Marketing Measurement Crisis}
\label{sec:measurement-crisis}
Every marketer has the same question: Did it work?  Did our price change increase sales, or was it simply seasonal demand?  Has our new digital channel eroded existing ones, or has it expanded the pie?  These are important questions.  Answering them correctly is the foundation of accountability and wise investing.  However, clear-cut answers are notoriously difficult to find.  The world does not stop while we conduct our campaigns.  Competitors reacted.  Trends shift.  Customers change.  The central challenge of marketing measurement is to distinguish the true causal impact of our actions from the background noise.

This book is about meeting that challenge. We demonstrate how to use panel data---observations of the same entities over time---to build credible causal inference practice. We move beyond simplistic before-and-after comparisons, which can mislead. Instead, we deploy modern econometric methods tailored to marketing data's unique complexities. We explore powerful techniques, from workhorses like difference-in-differences to synthetic controls and machine learning. Our goal is to provide conceptual understanding and practical wisdom to measure what matters, moving from correlation to causation, from guesswork to solid evidence.

Consider a modern CMO facing a well-known paradox. Her company has vast data: clickstreams tracing every customer journey, impression logs recording millions of ad exposures, transaction histories spanning decades, loyalty card data connecting behaviour to demographics. Yet when the board asks the most fundamental strategic question---did our recent loyalty programme work, and should we expand it?---she struggles to respond confidently. The data are abundant, but the insights are elusive.

The failure is not due to effort or sophistication.  Marketing analytics teams use advanced machine learning algorithms.  These algorithms forecast customer churn, recommend personalised products, and optimise bidding strategies in real-time auctions.  They do a good job forecasting within the existing system.  They determine which customers will respond to an offer, which creative will result in the most clicks, and which price point will maximise short-term revenue.  They cannot, and were never designed to, answer causal questions about strategic interventions.  They can't tell us what would happen if we changed the system.

 This is an important distinction.  Predicting that customers who visit the account cancellation page will churn allows us to focus retention efforts.  However, it says nothing about whether offering those customers a discount will reduce churn.  High-churn customers may be fundamentally different in ways that no discount can change.  The link between visiting the cancellation page and churning could point to a common cause -- dissatisfaction -- that manifests in both behaviours.  Predictions cannot be used to guide strategy unless the causal mechanism is understood.

 Marketing is experiencing a causal measurement crisis because traditional methods cannot handle how marketing actually works.  Begin with endogeneity.  Firms do not allocate marketing budgets at random.  They ramp up advertising when they anticipate high demand.  They run promotions in response to competitive threats.  They introduce loyalty programmes in areas where customer lifetime value is already increasing.  These decisions imply that simple correlations between marketing actions and outcomes confuse cause and effect.  Methods that work in cross-sectional settings, where we condition on observed pre-treatment covariates, fail when the confounding variables change over time.

 Dynamics exacerbates the problem.  An ad campaign does not have immediate impact.  Direct response advertising can increase sales within days.  Brand awareness grows gradually through repeated exposures.  Habit formation can take several weeks or months.  Carryover and adstock models from the marketing mix tradition have long acknowledged this reality.  However, these dynamic effects make identification more difficult than functional form assumptions would suggest.  Consumers respond to anticipated future prices rather than current prices.  Firms adjust their strategies in anticipation of competitor actions.  These intertemporal linkages eliminate any possibility of evaluating a marketing intervention by comparing a single pre-treatment period to a single post-treatment period.

Finally, spillovers are everywhere. Marketing actions frequently violate the stable unit treatment value assumption (SUTVA) that underpins most causal inference frameworks \citep{rubin1980randomization}. A customer who joins a loyalty programme may refer friends, generating positive spillover effects on untreated units.  A retailer running a local promotion draws customers from neighbouring regions, resulting in geographic spillovers.  When one company increases advertising, competitors respond by adjusting their own marketing mix, resulting in strategic spillover.  The causal effect of treating one unit is dependent on how the other units are treated.  This violates the independence assumption, which allows for clean causal identification in randomised experiments.

Traditional approaches to marketing measurement struggle to address these challenges.  Cross-sectional methods based on observable selection cannot account for time-invariant or slow-moving unobservables such as brand equity, store quality, or persistent consumer preferences, all of which influence marketing decisions and outcomes.  Simple before-and-after comparisons cannot differentiate the impact of a marketing intervention from secular trends, seasonality, or concurrent shocks.  Randomised controlled trials provide clean identification when possible, but they have limitations in marketing settings.  Spillovers between treated and control units may contaminate estimates.  Short experimental durations may miss long-term effects.  Ethical concerns may limit the interventions we can randomise.  Finally, the external validity of tightly controlled experiments may not apply in natural field settings.

 Industry practices frequently rely on marketing mix models.  They approach the problem differently, defining flexible functional forms (often with distributed lags to capture dynamics) and estimating them using aggregate time-series data.  These models have proven useful for quantifying the historical relationship between marketing inputs and outcomes; however, they face identification challenges when multiple marketing variables interact and functional form assumptions are strong.  Furthermore, traditional marketing mix models struggle to identify the causal effect of specific, discrete interventions such as the launch of a loyalty programme or a change in pricing strategy.  Attribution models, which are becoming more common in digital marketing platforms, track customer touchpoints and assign credit to various marketing contacts; however, they are also fundamentally observational exercises that make strong assumptions about the absence of unmeasured confounders and spillovers across channels.

 Panel data methods provide a bridge between the gold standard of randomised experiments and the often fragile inferences derived from observational data that lack a clear strategy for dealing with unobserved confounders.  Panel methods use repeated observations on the same units over time to control for time-invariant unobservables using fixed effects.  They identify causal effects by observing common trends or parallel evolution in treatment and control groups.  They estimate dynamic effects by observing outcomes over longer time periods.  They accommodate more diverse patterns of treatment adoption than two-group, two-period designs.  The modern panel data toolkit combines traditional econometric insights with recent advances in difference-in-differences, synthetic control methods, factor models, and machine learning to provide reliable causal estimates in observational marketing scenarios.

Our approach in this book is largely design-based, focusing on credible measurement of causal effects from specific interventions. This contrasts with the structural tradition, common in economics and marketing, which first constructs a theoretical model of behaviour before estimating its deep parameters.

The \citet{berry1995automobile} demand model for differentiated products exemplifies the structural approach.  A BLP model specifies a consumer's utility function and estimates demand elasticities using market-level data, taking price endogeneity into account.  Its objective is to recover the fundamental parameters of consumer preference.  Once estimated, these parameters enable broad counterfactual simulations, such as predicting market shares following a merger or a price change for all products.  This power comes at the expense of making significant assumptions about the utility function and market equilibrium.

Our focus is more practical. We prioritise transparent, credible identification of what an effect is, applying experimental design principles to observational data. To assess the effectiveness of a loyalty programme, we do not require a comprehensive consumer choice model. We do, however, require a clear theory of the assignment mechanism and counterfactuals. This is not measurement without theory, but measurement with minimal theory---enough structure to define the causal question and identify the effect, without requiring a complete model of consumer optimisation.

 This book systematically develops these tools, with a focus on the unique characteristics of marketing applications that provide both opportunities and challenges for causal inference.  Marketing generates rich panel data, such as store-level sales tracked over quarters or years, customer purchase histories spanning multiple transactions, market-level advertising, and outcomes measured across geographies and time.  However, marketing exhibits the three core challenges outlined above, namely endogenous decision-making, dynamic effects, and spillovers, in particularly acute forms.  Instead of assuming these realities, the methods we develop must confront them head on.

\subsection*{What This Book Is Not}

Before proceeding, it is critical to establish a clear understanding of scope and positioning.  This book is not an introduction to panel econometrics.  We assume you are familiar with fixed effects regression, basic matrix notation, and standard inference concepts.  Readers seeking foundational econometric training should consult a standard graduate textbook before diving into the panel-specific methods we develop here.  Part I provides a refresher on causal frameworks and panel notation, but it is not a substitute for prior knowledge.

 This book is not a machine learning cookbook.  We use machine learning tools such as random forests, lassos, and gradient boosting to identify causal relationships via nuisance function estimation or heterogeneous effect discovery.  However, we do not advocate ML as a replacement for research design.  A causal forest will not save you from confusion.  Double machine learning works due to Neyman orthogonalisation, not algorithmic sophistication.  Design-based identification comes first; ML is a tool, not a solution.

 Finally, this book is not a structural modelling textbook.  We focus on the design-based identification of well-defined causal effects, such as the impact of a loyalty programme on sales or the effect of advertising on purchase, rather than the recovery of deep preference parameters or the estimation of equilibrium models.  Structural approaches have their place, but we prefer transparent, assumption-explicit methods that value credibility over generality.  We want to know "what is the effect?" not "what are the primitives of consumer utility?"
