\section{Motivating Examples: Three Marketing Challenges}
\label{sec:motivating-examples}

To ground the abstract discussion of panel methods in concrete marketing problems, we consider three hypothetical scenarios that motivate the methods developed in subsequent chapters. Each scenario illustrates a distinct set of challenges and maps to a different constellation of panel data tools. While stylised, these examples reflect real measurement challenges practitioners face.

\subsection*{Example 1: Evaluating a Loyalty Programme with Staggered Rollout}

Consider a hypothetical retail chain with 500 stores in various regions and three years of quarterly sales data.  To increase customer retention and lifetime value, the chain launches a loyalty programme that rewards purchases with points that can be redeemed for future discounts.  Rather than launching the program all at once, the company takes a phased approach: 100 stores in the first year, 200 more in the second year, and 150 more in the third.  The remaining 50 stores, most of which are small and remote, never receive the programme and instead serve as controls.

 The staggered rollout reflects both operational constraints and strategic considerations.  Early adopters are typically larger stores in high-income areas where management anticipates strong program uptake.  Later adopters include stores in more competitive markets, where the company hopes the program will help it defend market share.  This non-random assignment results in selection bias: programme stores differ systematically from non-programme stores in ways that affect sales even when the programme is not in effect.  Simply comparing sales in program stores to non-program stores would conflate the programme effect with these pre-existing differences.

 Additional complications arise during the evaluation.  Spillovers are significant: customers who join may refer friends or family, resulting in positive peer effects, whereas customers from nearby non-programme stores may switch to programme stores to earn rewards.  The programme's effect is unlikely to be immediate or consistent — initial enrolment may be slow, habit formation takes time, and switching costs rise gradually as customers accumulate points.  There may even be anticipation effects if rumours about the impending launch circulate ahead of time.  The effect is likely to vary by store type, with affluent, low-competition neighbourhoods responding differently than saturated urban markets where customers already have multiple loyalty options.

This scenario maps naturally to modern panel data methods. The staggered rollout calls for difference-in-differences estimators that accommodate heterogeneous adoption timing (Chapter \ref{ch:did}). Event-study specifications (Chapter \ref{ch:event}) plot treatment effects over time and enable pre-trend tests. Spillover models (Chapter \ref{ch:spillovers}) estimate geographic externalities. Causal forests (Chapter \ref{ch:ml-nuisance}) uncover heterogeneity across store types. Chapters \ref{ch:design-diagnostics} and \ref{ch:inference} develop the diagnostic workflow including placebo tests, leave-one-out analyses, and sensitivity analyses.

What might such an analysis reveal? In this hypothetical case, suppose the estimated average treatment effect were eight per cent across all programme stores and quarters. This aggregate effect would mask important dynamics: an initial effect of just two per cent in the first quarter post-launch, growing to eight per cent after four quarters and stabilising thereafter. Spillovers might be positive but modest — sales in non-programme stores within five kilometres of a programme store rising by two per cent, suggesting word-of-mouth effects. Heterogeneity analysis might reveal effects concentrated in high-income, low-competition areas (twelve per cent increase) with near-zero effects in saturated urban markets. These richer insights would guide not just whether to expand the programme, but where to expand it and how to manage expectations about the timeline for seeing results.

\subsection*{Example 2: Measuring Television Advertising Carryover in the Digital Age}

Consider a consumer packaged goods brand that wants to understand the causal effect of TV advertising on sales while controlling for carryover effects and digital channel interactions.  The hypothetical data consists of weekly observations for 50 designated market areas over a 100-week period, including gross rating points (GRPs), online search volume, social media mentions, and sales.  The advertising agency strategically varies TV spending, with higher levels during product launches, in markets with active competitors, and when previous sales trends indicate rising demand.

 The first challenge is the endogeneity of television spending.  Markets that receive a lot of TV advertising in a given week may be very different from markets that get little advertising.  Even if we use fixed effects to control for time-invariant market characteristics, time-varying confounds such as competitor actions, local economic shocks, and seasonal patterns may influence both advertising decisions and sales, resulting in spurious correlation.  A second challenge is carryover: the effects of TV advertisements do not appear and disappear instantly.  Some viewers react quickly by searching online or going to a store.  Others save the information and act several days or weeks later.  Brand awareness grows through repeated exposures and gradually declines in the absence of advertising.  Specifying the functional form of this carryover is complex and has been the subject of extensive research in the marketing mix modelling tradition.  Third, cross-channel effects complicate the situation.  TV advertising may increase online searches, resulting in increased sales.  When we estimate the total effect of TV on sales, we include both the direct and indirect effects mediated by search.  However, if we control for search in a regression, we risk blocking the causal pathway and underestimating the TV effect.  Understanding these mediated effects is substantively significant but econometrically challenging.  Fourth, measurement concerns abound:  Nielsen television ratings are based on panels that may not accurately represent the entire population, sales data are aggregated from retail scanner panels that have their own coverage gaps, and seasonal effects (holidays, weather, major events) cause non-stationarity that must be distinguished from treatment effects.

 This scenario is well-suited to a variety of panel methods.  Synthetic control methods (Chapters \ref{ch:sc} and \ref{ch:generalized-sc}) create customised control groups for treated markets.  Distributed lag models (Chapter \ref{ch:dynamics}) define carryover structure.  High-dimensional control methods (Chapter \ref{ch:high-dim}) use data-driven variable selection to address multiple potential confounders.  The chapters \ref{ch:inference} and \ref{ch:design-diagnostics} discuss cluster-robust inference, placebo tests, and sensitivity analyses for carryover assumptions.

 In a hypothetical analysis, television advertising could boost sales by 5\% during the campaign week, with a three-week half-life.  Online search may mediate approximately 40\% of the total effect, with TV driving search and search driving sales.  Competitor advertising may partially offset the own-brand effect, reducing it by 20\% when competitors simultaneously increase spending.  According to memory and persuasion theories, emotional appeals may have a stronger carryover than informational appeals.  Such insights would help guide budget allocation, creative strategy, and competitive response.

\subsection*{Example 3: Platform Market Entry and Competitive Dynamics}

Consider a hypothetical food delivery platform (e.g., DoorDash, Deliveroo, or Uber Eats) that expands into 30 new cities in two years.  The company tracks restaurant revenues on a monthly basis in both entry and comparison cities that do not use the platform.  The data covers 50 cities over 36 months, resulting in a panel with staggered treatment timing.  The firm wants to estimate the causal effect of platform entry on restaurant revenue while controlling for competitive dynamics and general equilibrium effects.

 Several challenges complicate the analysis.  Because each city is unique, exact matches between treated and control cities are impossible.  The firm chooses entry cities based on market size, demographics, competitive landscape, and regulatory requirements.  This creates selection bias.  Entry occurs at different times in different cities, with larger, more appealing markets entering first.  Once the platform enters a city, incumbent platforms (existing competitors) may respond by lowering commissions, increasing marketing, or improving service quality, thereby mitigating the treatment effect and inducing competitive spillovers.  Furthermore, platform entry has an impact not only on the restaurants that join the platform, but on the entire restaurant ecosystem: consumers may dine out more frequently (category expansion), delivery drivers may shift labour supply, and restaurants that do not join the platform may see changes in foot traffic or delivery orders via third-party services.

This scenario motivates several panel methods. Synthetic control (Chapter \ref{ch:sc}) constructs control cities from weighted averages of never-treated cities, with inference via permutation tests. Synthetic difference-in-differences (Chapter \ref{ch:generalized-sc}) combines unit and time weights for staggered entry settings. Factor models (Chapter \ref{ch:factor}) handle unobserved common shocks affecting all cities. Spillover models (Chapter \ref{ch:spillovers}) quantify competitive responses. We develop these methods and their diagnostics in Chapters \ref{ch:did} through \ref{ch:spillovers}.

Hypothetical findings might show platform entry increasing restaurant revenues by fifteen per cent on average, with substantial heterogeneity. Small, independent restaurants could see twenty-five per cent gains from expanded reach, while chains with established delivery operations might see only five per cent gains. The competitive response from incumbent platforms could offset the effect by roughly thirty per cent in markets where incumbents lower commissions or increase promotions. General equilibrium effects might be positive — the category expanding as consumers order more frequently — suggesting platform entry creates value rather than merely redistributing it, with implications for regulatory policy and market structure.

These three hypothetical examples illustrate the range of marketing questions panel data methods can address — selection bias, dynamics, spillovers, heterogeneity, measurement error, competitive interactions. Each will recur in subsequent chapters as we develop the technical methods and diagnostic workflows for credible causal inference.
