\section{Advertising Incrementality: Geo-Experiments}
\label{sec:geo-experiments}

The measurement of advertising effectiveness is plagued by the confusion between attribution and incrementality. Attribution credits a sale to a touchpoint, while incrementality measures the causal lift generated by that touchpoint.

\subsection*{Estimand Definition}
We define the Incremental Lift formally. Let $Y_{it}(w)$ denote revenue in geography $i$ at time $t$ under binary treatment $w \in \{0,1\}$, where $w=1$ indicates ad exposure and $w=0$ indicates no exposure (a ``dark'' hold-out). We focus on the extensive margin: does advertising generate incremental revenue relative to no advertising? The intensive margin---how much more spend yields how much more revenue---requires dose-response methods (Chapter~\ref{ch:continuous}).

\begin{definition}[Incremental Lift]\label{def:incremental-lift}
The Incremental Lift is the Average Treatment Effect on the Treated (ATT):
\[
\tau = \mathbb{E}[Y_{it}(1) - Y_{it}(0) \mid W_i = 1],
\]
where $Y_{it}(1)$ is revenue under ad exposure and $Y_{it}(0)$ is counterfactual revenue with zero exposure.
\end{definition}

\begin{definition}[Incremental Return on Ad Spend]\label{def:iroas}
The business metric of interest is Incremental Return on Ad Spend:
\[
\text{iROAS} = \frac{\sum_{i \in \text{treated}} \sum_{t \in \text{post}} \hat{\tau}_{it}}{\text{Total Ad Spend}},
\]
where $\hat{\tau}_{it}$ is the estimated incremental revenue (in currency units) for unit $i$ at time $t$. An iROAS of 2.0 means each pound spent generated two pounds of incremental revenue. This differs fundamentally from MMM elasticities or multi-touch attribution weights, which are often correlational rather than causal.
\end{definition}

\subsection*{Identification Strategy}
To identify the ATT, we rely on the assumption that we can construct a valid counterfactual for the treated regions.
\begin{assumption}[Parallel Trends for Geo-Experiments]\label{assump:geo-parallel-trends}
In the absence of the ad campaign, the trend in untreated potential outcomes is the same for treated and control regions:
\[
\mathbb{E}[Y_{it}(0) - Y_{i,t-1}(0) | W_i = 1] = \mathbb{E}[Y_{it}(0) - Y_{i,t-1}(0) | W_i = 0], \quad \forall t.
\]
This assumption is testable in the pre-treatment period but must be assumed to hold in the post-treatment period.
\end{assumption}

\begin{assumption}[No Interference Across Regions]\label{assump:geo-sutva}
The potential outcome of region $i$ depends only on its own treatment status, not on the treatment status of other regions:
\[
Y_{it}(w_i, w_{-i}) = Y_{it}(w_i), \quad \forall w_{-i}.
\]
This assumption fails when ads in treated regions drive sales in control regions (e.g., customers travel across boundaries), when platform algorithms redistribute demand geographically, or when competitors respond asymmetrically to the campaign. Violations bias estimates downward if treatment ``leaks'' to controls, or in either direction under strategic responses. Buffer regions---excluding geographies adjacent to treated areas---provide a partial safeguard; see Chapter~\ref{ch:spillovers} for formal treatment of interference.
\end{assumption}

\subsection*{Temporal Structure: Static vs.\ Dynamic Effects}

The taxonomy in Section~\ref{sec:taxonomy} distinguishes static from dynamic treatment effects. Many geo-experiments implicitly assume static effects: the outcome $Y_{it}(w_t)$ depends only on contemporaneous exposure. In practice, advertising often exhibits carryover---effects that persist or accumulate beyond the exposure period.

\begin{remark}[Carryover and Post-Period Window]\label{rem:geo-carryover}
The choice of post-period window materially affects iROAS estimates. Consider two scenarios:
\begin{enumerate}
\item \textbf{Performance advertising} (e.g., paid search, retargeting): Effects are largely contemporaneous. A short post-period (4--8 weeks during the campaign) captures most of the lift.
\item \textbf{Brand advertising} (e.g., television, out-of-home): Effects accumulate in a brand equity stock that decays slowly. A short post-period underestimates total lift; extending measurement to 12--26 weeks post-campaign captures delayed conversions and habit formation.
\end{enumerate}
When carryover is substantial, the path-dependent framework $Y_{it}(\mathbf{w}^t)$ from Chapter~\ref{ch:dynamics} applies. Distributed lag models or adstock transformations (Section~\ref{sec:mmm}) can decompose short-run and long-run effects. At minimum, analysts should report iROAS at multiple post-period windows to assess sensitivity.
\end{remark}

\subsection*{Design and Estimation}
The gold standard design is the Geo-Experiment. We select a set of geographic units---DMAs, postcode sectors, or store catchments---and randomise them into treatment and control groups. The treatment group receives the ad campaign, while the control group receives no advertising exposure (a ``dark'' hold-out).

\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{images/fig_geo_experiment_schematic.pdf}
\caption{Geo-experiment design schematic. The timeline shows the division into pre-treatment (baseline) and treatment periods. Geographic units are assigned to treatment (ad exposure) or control (hold-out), allowing for difference-in-differences or synthetic control estimation.}
\label{fig:geo-experiment}
\end{figure}

For observational settings where randomisation is impossible, we use the Observational Geo-Panel, exploiting natural variation in ad budgets across regions. Table~\ref{tab:geo-design-comparison} compares the main design options.

\begin{table}[htbp]
\begin{tighttable}
\centering
\caption{Design comparison for advertising incrementality measurement}
\label{tab:geo-design-comparison}
\begin{tabularx}{\textwidth}{Y Y Y Y}
\toprule
\textbf{Design} & \textbf{Advantages} & \textbf{Limitations} & \textbf{When to Use} \\
\midrule
Randomised hold-out & Gold standard, unbiased & Opportunity cost, requires scale & New campaigns, large budgets \\
Pair-matched markets & Balances on pre-period outcomes & Parallel trends still required & Few treated units, no full randomisation \\
Synthetic control & Single treated unit OK & Donor pool quality critical & Market-level tests, rare events \\
SDID & Combines SC + DiD strengths & Requires both unit and time weights & Multiple treated units \\
\bottomrule
\end{tabularx}
\end{tighttable}
\end{table}

\begin{remark}[Power and Minimum Detectable Effect]\label{rem:geo-power}
Geo-experiments operate with small effective sample sizes. With $N_{\text{treated}} = 5$ DMAs and cluster-level randomisation, the degrees of freedom for inference are far below a typical user-level A/B test. Before committing to a design, analysts should compute the minimum detectable effect (MDE) at 80\% power. As a rough heuristic, detecting a 5\% lift in weekly revenue with $N = 50$ total DMAs (25 treated, 25 control) and a 52-week pre-period requires baseline coefficient of variation below 0.15. Underpowered experiments produce wide confidence intervals and inconclusive results. When MDE exceeds the expected lift, consider pooling more regions, extending the pre-period, or accepting that the experiment will be exploratory rather than confirmatory.
\end{remark}

The preferred estimators are Synthetic Control (SC) or Synthetic Difference-in-Differences (SDID). These methods construct a synthetic counterfactual by weighting control units to match the pre-treatment trajectory of the treated units.

The estimation proceeds in three steps. First, we define the pre-treatment period and validate the quality of the synthetic match. Second, we estimate the synthetic counterfactual for the post-treatment period. Third, we calculate the lift as the difference between the observed and synthetic outcomes.

\subsection*{Diagnostic Checklist}

A valid geo-experiment requires rigorous diagnostics. The following checklist operationalises the general diagnostic framework from Chapter~\ref{ch:design-diagnostics} for the geo-experiment setting.

\begin{tcolorbox}[colback=gray!5!white,colframe=gray!75!black,title=Box 18.2: Geo-Experiment Diagnostic Checklist]
\textbf{1. Pre-period balance:} Report standardised mean differences (SMD) on baseline sales, population, and demographics. Target $|\text{SMD}| < 0.1$.

\textbf{2. Pre-trend test:} Conduct a joint F-test on all pre-treatment event-time coefficients. Report the p-value and interpret non-rejection cautiously (Section~\ref{sec:pretrends-placebo}).

\textbf{3. Synthetic control fit:} Compute $\text{RMSPE}_{\text{pre}}$ and verify it is less than 5\% of mean baseline sales.

\textbf{4. Weight concentration:} Calculate the effective number of donors $N_{\text{eff}} = 1/\sum_j w_j^2$. Target $N_{\text{eff}} > 3$ (Section~\ref{sec:influence-stability}).

\textbf{5. Placebo tests:} Run in-space placebos (apply SC to each donor) and in-time placebos (use a pseudo-treatment date). Report the rank of the treated unit.

\textbf{6. Leave-one-out:} Re-estimate excluding each major donor. Flag estimates that change by more than 20\%.

\textbf{7. Spillover check:} Test for effects in geographies adjacent to treated regions (buffer analysis, Section~\ref{sec:support-exposure}).
\end{tcolorbox}

\subsection*{Extended Case Study: Regional Television Campaign}
We illustrate the geo-experiment protocol with a retailer testing a regional television campaign.

\paragraph{Setting and Data.} A national retailer tests a TV campaign in 5 DMAs (treated) against 45 control DMAs. The data consist of weekly store-level sales aggregated to the DMA level. The pre-period spans 52 weeks, providing a stable baseline. The treatment period is 8 weeks.

\paragraph{Design.} We apply SDID with penalised synthetic control weights. The regularisation parameter is selected via cross-validation on the pre-period fit.

\paragraph{Results.} The estimated lift is 8.2\% (95\% CI: 3.1\%, 13.3\%). Total incremental revenue is \pounds 2.4 million against campaign spend of \pounds 1.0 million, yielding iROAS = 2.4.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{images/fig_app_sc_gap_weights.pdf}
\caption{Synthetic Control estimation results. Top panel: Gap plot showing the difference in sales between the treated DMA and the synthetic counterfactual. Bottom panel: Distribution of donor weights, indicating which control DMAs contribute most to the counterfactual.}
\label{fig:app-sc-gap}
\end{figure}

\paragraph{Diagnostics.} Pre-period RMSPE is 2.1\% of baseline sales, well below the 5\% threshold. The pre-trend joint F-test yields $p = 0.67$, failing to reject parallel trends. Weight concentration gives $N_{\text{eff}} = 4.2$, indicating adequate donor diversity. Leave-one-out analysis shows that no single DMA changes the estimate by more than 15\%.

In the in-space placebo distribution, the treated unit ranks 4th out of 46, corresponding to a placebo p-value of $p = 0.087$. This is marginally significant at the 10\% level but does not reach conventional 5\% significance.

\paragraph{Conclusion.} The campaign generated a point estimate of 8.2\% lift with an iROAS of 2.4. Diagnostics are generally supportive: pre-period fit is excellent, parallel trends are not rejected, and the estimate is stable to leave-one-out perturbations. However, the placebo p-value of 0.087 provides only moderate evidence against the null. We conclude that the evidence is suggestive but not definitive. A larger-scale replication with more treated DMAs would provide sharper inference. The business decision to continue investment should weigh this uncertainty against the opportunity cost of inaction.
