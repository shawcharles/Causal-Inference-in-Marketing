\section{Marketplace Seller Interventions}
\label{sec:seller-interventions}

Marketplace platforms intervene on sellers through fee changes, promotional tools, quality badges, and policy enforcement. These interventions affect not only the treated sellers but also buyers (through prices and selection) and competing sellers (through market share shifts). Estimating the causal effect of seller interventions requires accounting for these equilibrium spillovers.

\begin{remark}[Seller Interventions in the Taxonomy]\label{rem:seller-taxonomy}
In the taxonomy of Section~\ref{sec:taxonomy}, seller interventions are primarily an \emph{interference} problem: treating one seller shifts demand away from competitors, violating SUTVA. The effect on the treated seller includes business stolen from untreated sellers; the market-level effect nets out these transfers. For the general platform experiment framework, see Section~\ref{sec:platform-experiments}. Seller interventions may also affect rankings (Section~\ref{sec:ranking-algorithms}) and interact with pricing decisions (Section~\ref{sec:price-elasticity}).
\end{remark}

\subsection*{Estimand: Seller and Market Effects}

We distinguish direct effects on treated sellers from spillover effects on the market.

\begin{definition}[Direct Seller Effect]\label{def:direct-seller}
Let $W_j \in \{0, 1\}$ indicate whether seller $j$ receives the intervention (e.g., fee reduction, promotional tool). The direct effect on seller $j$'s outcome $Y_j$ (e.g., sales, revenue) is:
\[
\tau_{\text{direct}} = \mathbb{E}[Y_j(1, \mathbf{W}_{-j}) - Y_j(0, \mathbf{W}_{-j}) | W_j = 1],
\]
holding other sellers' treatments fixed.
\end{definition}

\begin{definition}[Spillover Effect on Competing Sellers]\label{def:seller-spillover}
The spillover effect on untreated seller $k$ from treating seller $j$ is:
\[
\tau_{\text{spillover}} = \mathbb{E}[Y_k(0, W_j = 1) - Y_k(0, W_j = 0)].
\]
In competitive markets, this is typically negative: treating one seller harms competitors.
\end{definition}

\begin{definition}[Buyer Welfare Effect]\label{def:buyer-welfare}
Let $V_i$ be buyer $i$'s surplus (e.g., consumer surplus, transaction value). The buyer welfare effect is:
\[
\tau_{\text{buyer}} = \mathbb{E}[V_i(\mathbf{W} = \mathbf{1}) - V_i(\mathbf{W} = \mathbf{0})],
\]
comparing buyer outcomes when all sellers are treated vs. none.
\end{definition}

The platform cares about total market outcomes: seller revenue, buyer welfare, and platform take rate. These may move in different directions.

\subsection*{Identification Challenge: Competitive Spillovers}

Seller interventions create competitive externalities. Treating one seller shifts demand away from competitors.

\begin{assumption}[Competitive Spillovers]\label{assump:competitive-spillovers}
In a marketplace with $J$ sellers, treating seller $j$ affects seller $k$'s outcomes:
\[
\frac{\partial Y_k}{\partial W_j} \neq 0, \quad \text{for } k \neq j.
\]
The sign depends on the intervention: fee reductions or promotions typically create negative spillovers (business stealing); quality improvements may create positive spillovers (market expansion).
\end{assumption}

Naive randomisation at the seller level estimates the direct effect but misses spillovers. If spillovers are negative, the direct effect overstates the market-level impact.

\subsection*{Identification Strategy 1: Market-Level Randomisation}

Randomise the intervention at the market level to capture full equilibrium effects.

\begin{definition}[Market-Level Experiment]\label{def:market-experiment}
Partition the platform into $M$ markets (e.g., cities, product categories). Randomly assign markets to treatment (all sellers receive intervention) or control (no sellers receive intervention). The market-level effect is:
\[
\hat{\tau}_{\text{market}} = \frac{1}{|\mathcal{M}_1|} \sum_{m \in \mathcal{M}_1} \bar{Y}_m - \frac{1}{|\mathcal{M}_0|} \sum_{m \in \mathcal{M}_0} \bar{Y}_m,
\]
where $\bar{Y}_m$ is the average outcome in market $m$.
\end{definition}

\begin{assumption}[No Cross-Market Spillovers]\label{assump:no-cross-market}
Outcomes in market $m$ depend only on treatments within market $m$:
\[
Y_{jm}(\mathbf{W}_m, \mathbf{W}_{-m}) = Y_{jm}(\mathbf{W}_m, \mathbf{W}'_{-m}), \quad \forall \mathbf{W}_{-m}, \mathbf{W}'_{-m}.
\]
\end{assumption}

This assumption holds when markets are geographically or categorically separated. It fails when sellers operate across markets or when buyers substitute across markets.

\subsection*{Identification Strategy 2: Seller Cluster Randomisation}

When market-level randomisation is infeasible, cluster sellers into groups with strong within-cluster competition.

\begin{definition}[Seller Cluster Randomisation]\label{def:seller-cluster}
Partition sellers into clusters $\mathcal{C}_1, \ldots, \mathcal{C}_K$ based on competitive proximity (e.g., same subcategory, same price tier). Randomly assign clusters to treatment or control. The cluster-level effect captures within-cluster spillovers:
\[
\hat{\tau}_{\text{cluster}} = \frac{1}{|\mathcal{K}_1|} \sum_{k \in \mathcal{K}_1} \bar{Y}_k - \frac{1}{|\mathcal{K}_0|} \sum_{k \in \mathcal{K}_0} \bar{Y}_k.
\]
\end{definition}

Cluster definition is critical: clusters should contain close competitors. Use product similarity, price overlap, or buyer co-consideration data to define clusters.

\subsection*{Identification Strategy 3: Difference-in-Differences with Staggered Rollout}

If the intervention rolls out to sellers over time, staggered DiD exploits timing variation.

\begin{assumption}[Parallel Trends for Seller Rollout]\label{assump:seller-did}
In the absence of the intervention, seller outcomes would follow parallel trends:
\[
\mathbb{E}[Y_{jt}(0) - Y_{j,t-1}(0) | G_j = g] = \mathbb{E}[Y_{jt}(0) - Y_{j,t-1}(0) | G_j = g'], \quad \forall g, g',
\]
where $G_j$ is the cohort (rollout wave) for seller $j$.
\end{assumption}

Use heterogeneity-robust estimators (Chapter~\ref{ch:did}). Note that staggered DiD captures the direct effect plus spillovers to not-yet-treated sellers, but not the full equilibrium effect.

\subsection*{Estimation}

For market-level experiments, use difference-in-means with market-level clustering. With few markets, use randomisation inference.

For seller cluster randomisation, aggregate outcomes to the cluster level and use cluster-robust standard errors.

For staggered rollout, apply Callaway-Sant'Anna or Sun-Abraham estimators. Include seller fixed effects and time fixed effects:
\[
Y_{jt} = \alpha_j + \gamma_t + \tau \cdot W_{jt} + X_{jt}'\beta + \varepsilon_{jt}.
\]

\subsection*{Decomposing Direct and Spillover Effects}

When both treated and control sellers are observed within the same market, decompose the total effect.

\begin{definition}[Effect Decomposition]\label{def:effect-decomposition}
In a partial-treatment design where fraction $p$ of sellers are treated:
\begin{align}
\text{Direct effect:} \quad & \hat{\tau}_{\text{direct}} = \bar{Y}_{\text{treated}} - \bar{Y}_{\text{control, no spillover}}, \\
\text{Spillover effect:} \quad & \hat{\tau}_{\text{spillover}} = \bar{Y}_{\text{control, with treated neighbours}} - \bar{Y}_{\text{control, no treated neighbours}}.
\end{align}
The total market effect is approximately $p \cdot \tau_{\text{direct}} + (1-p) \cdot \tau_{\text{spillover}}$.
\end{definition}

This decomposition requires variation in exposure to treated competitors, which can be constructed from the competitive network. Note that the linear approximation ignores higher-order effects (e.g., how the spillover effect itself varies with treatment intensity) and assumes spillovers are proportional to exposure. In practice, competitive dynamics may be nonlinear.

\begin{remark}[Dynamic Effects of Seller Interventions]\label{rem:seller-dynamics}
Seller interventions may have temporal dynamics beyond immediate effects:
\begin{enumerate}
\item \textbf{Learning and adjustment.} Sellers adjust pricing, inventory, and listing strategies over time in response to changed incentives. Short-run effects may overstate or understate long-run equilibrium effects.
\item \textbf{Entry and exit.} Fee reductions may attract new sellers; fee increases may cause exit. The seller composition in treated markets diverges from control over time.
\item \textbf{Buyer habit formation.} Improved selection or lower prices may attract buyers who develop purchasing habits, creating persistent demand even after the intervention ends.
\end{enumerate}
Short-run experiments capture immediate responses; longer observation windows or staggered rollouts (Chapter~\ref{ch:did}) are needed to assess persistence and equilibrium effects.
\end{remark}

\subsection*{Diagnostic Checklist}

\begin{tcolorbox}[colback=green!5!white,colframe=green!50!black,title=Box 18.16: Seller Intervention Diagnostic Checklist]
\paragraph{For Market-Level Experiments:}
\begin{itemize}
    \item Market independence: Test for cross-market spillovers using outcomes in control markets adjacent to treated markets.
    \item Market balance: Compare market-level covariates (size, seller count, category mix) across treatment arms.
    \item Few-market inference: With $< 20$ markets, use randomisation inference.
\end{itemize}

\paragraph{For Seller Cluster Randomisation:}
\begin{itemize}
    \item Cluster definition: Validate that clusters contain close competitors (e.g., high cross-elasticity).
    \item Within-cluster balance: Check seller characteristics are balanced across treated and control clusters.
    \item Cross-cluster spillovers: Test for effects on control clusters near treated clusters.
\end{itemize}

\paragraph{For Effect Decomposition:}
\begin{itemize}
    \item Competitive network: Define which sellers compete with which (same category, price tier, geography).
    \item Exposure measure: Compute each control seller's exposure to treated competitors.
    \item Sign consistency: Verify that spillover effects have the expected sign (negative for business stealing, positive for market expansion).
\end{itemize}
\end{tcolorbox}

\subsection*{Case Study: Marketplace Fee Reduction}

We illustrate market-level randomisation with a hypothetical e-commerce marketplace. The numbers are illustrative and do not represent real data.

\paragraph{Setting.} A marketplace tests a 2 percentage point reduction in seller commission (from 15\% to 13\%) to stimulate seller activity. The goal is to estimate the effect on total marketplace GMV (gross merchandise value), accounting for competitive dynamics.

\paragraph{Design.} Market-level experiment across 40 cities. 20 cities receive the fee reduction for all sellers; 20 cities serve as control. Duration: 8 weeks.

\paragraph{Data.} 500,000 sellers across 40 cities; 50 million transactions. Outcomes: seller GMV, number of listings, average price, buyer transactions.

\paragraph{Results.} Market-level effects:
\begin{center}
\begin{tabular}{lcc}
\hline
Outcome & Treatment Effect & SE \\
\hline
Seller GMV & +8.4\% & 2.1\% \\
Number of listings & +12.1\% & 3.2\% \\
Average price & $-$1.8\% & 0.6\% \\
Buyer transactions & +5.2\% & 1.4\% \\
\hline
\end{tabular}
\end{center}
The fee reduction increased seller activity (more listings) and was partially passed through to buyers (lower prices), leading to more transactions.

\paragraph{Decomposition.} Within treated markets, we compare sellers by exposure to competing treated sellers. Sellers with few treated competitors show GMV +11.2\%, while sellers with many treated competitors show GMV +6.1\%. The difference (5.1 percentage points) reflects competitive spillovers: when all competitors also receive the fee reduction, the relative advantage is smaller.

\paragraph{Revenue Impact.} The 8.4\% GMV increase generates additional platform revenue of approximately \$4.2 million (at 13\% take rate). However, the 2 pp fee reduction on baseline GMV costs approximately \$6.8 million. Net platform revenue decreases by \$2.6 million.

\paragraph{Interpretation.} The fee reduction successfully stimulates marketplace activity: more listings, lower prices, more transactions. However, the direct revenue loss exceeds the indirect gain from higher GMV. The intervention is profitable only if: (1) the GMV increase persists after the fee reduction ends (habit formation); (2) new sellers acquired during the promotion have high lifetime value; or (3) the platform values buyer welfare beyond direct revenue. A longer-term analysis with seller and buyer retention outcomes would clarify the full ROI.
