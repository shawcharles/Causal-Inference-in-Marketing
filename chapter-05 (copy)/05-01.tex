\section{Motivation and Setup}
\label{sec:event-motivation}

Event-study designs organise panel data by \index{event time}event time rather than calendar time, indexing observations by their position relative to an intervention date. This simple reframing yields powerful diagnostic and substantive benefits. Event studies visualise the dynamic evolution of treatment effects, test whether treated and control units were on parallel trajectories before treatment, reveal anticipatory responses or delayed effects, and communicate causal narratives in a transparent, accessible format. In marketing applications, where interventions rarely produce immediate, constant effects, event studies are indispensable for understanding ramp-up periods, decay rates, carryover, and long-run impacts.

The logic of event-time analysis is straightforward. For each unit $i$, define the \index{adoption time}adoption time $G_i$ as the first period in which unit $i$ receives treatment. Event time $k = t - G_i$ measures the number of periods since (or until) adoption: $k = -2$ denotes two periods before adoption, $k = 0$ denotes the adoption period, $k = 3$ denotes three periods after adoption. By aligning units in event time rather than calendar time, event studies pool observations from units that adopted treatment at different calendar dates but are at the same point in their post-treatment trajectory. This pooling increases precision when treatment effects are homogeneous across cohorts. When effects are heterogeneous, pooling can introduce bias: the event-time coefficient $\theta_k$ becomes a weighted average of \index{cohort-specific effects}cohort-specific effects, with weights that depend on \index{cohort}cohort sizes and the panel structure. This is the event-study analogue of the TWFE problem discussed in Chapter~\ref{ch:did}. Event-time pooling enables estimation of dynamic treatment effect profiles even when individual cohorts are small or when calendar-time aggregations obscure dynamics, but the analyst should assess whether homogeneity is plausible.

A related concern is \index{composition bias}composition bias at long horizons. Event-time effects at large positive $k$ are identified only from early-adopting cohorts (late adopters have not yet reached that horizon), while effects at large negative $k$ are identified only from late-adopting cohorts (early adopters were not yet in the panel that far before adoption). If early and late adopters differ systematically, the event-time profile may reflect composition changes rather than true dynamics. Truncating the event window or reporting cohort-specific effects can diagnose this issue.

\textbf{Worked Example: Event-Time Alignment.} Consider three stores adopting a loyalty programme at different calendar times within a sample: Store A adopts in quarter 3, Store B in quarter 5, and Store C in quarter 7. In calendar time, their post-treatment observations occur in different quarters. In event time, all three stores contribute to $k = 0$ (the adoption quarter), $k = 1$ (one quarter post-adoption), $k = 2$ (two quarters post-adoption), and so on. Store A's quarter 5 observation corresponds to $k = 2$; Store B's quarter 5 observation corresponds to $k = 0$; Store C's quarter 5 observation corresponds to $k = -2$ (two quarters before adoption). By pooling across stores at each event time, we estimate $\theta_0$, $\theta_1$, $\theta_2$, etc., with contributions from multiple cohorts, increasing precision and revealing dynamics that calendar-time analysis would obscure.

Event studies are a natural extension of the difference-in-differences framework developed in Chapter~\ref{ch:did}. The canonical two-period DiD compares treated and control units before and after treatment, implicitly estimating a single average treatment effect that applies to all post-treatment periods. Event studies relax this restriction by estimating a separate treatment effect for each event time $k$, allowing the effect to vary over the post-treatment horizon and enabling tests for pre-trends by estimating effects for pre-treatment event times ($k < 0$). The connection to DiD is direct: the overall average treatment effect (ATT) estimated by DiD is a weighted average of the event-time effects $\theta_k$ estimated by an event study, and the choice between reporting a single ATT or a full event-time profile depends on the substantive question and the data structure.

\index{anticipation}Anticipation and \index{carryover}carryover, central concerns in marketing, motivate event-time analysis. Anticipation occurs when units respond to expected future treatment by altering behaviour in advance. Customers anticipating a loyalty programme launch may delay purchases to qualify for rewards, depressing pre-treatment outcomes relative to what they would have been absent the anticipation. This produces non-zero pre-treatment coefficients in the event study, violating the no-anticipation assumption underpinning causal identification (Chapter~\ref{ch:frameworks}). The sign of the anticipation effect depends on the mechanism: delayed purchases produce negative coefficients, while stockpiling in advance of a price increase produces positive coefficients. Carryover occurs when treatment effects persist or evolve over time. An advertising campaign may build brand awareness gradually, producing effects that grow over multiple quarters. A pricing change may trigger competitive responses that erode initial gains, producing effects that decay. Distributed lag models and structural dynamic panel models (Chapter~\ref{ch:dynamics}) provide parametric approaches to modelling carryover. Event studies offer a flexible, reduced-form alternative that imposes minimal restrictions on the lag structure, though they do assume that the dynamic profile $\{\theta_k\}$ is common across cohorts (homogeneous dynamic effects). When this assumption fails, cohort-specific event studies or interaction models are required.

Event studies also link marketing actions to stock market reactions. Financial event studies estimate abnormal returns in tight windows around announcements and attribute them to the new information the market receives about future cash flows. Customer satisfaction and innovation announcements are associated with positive abnormal returns, while some signals show limited or transitory effects once risk and benchmarks are accounted for \citep{fornell2006customer,mizik2009valuing,jacobson2009financial,sood2009innovations}. Financial event studies differ methodologically from the panel event studies developed in this chapter: they use market models to define counterfactual returns rather than parallel trends, and inference typically relies on cross-sectional independence rather than clustering. We focus on panel event studies; financial event studies are a complementary tool for quantifying the capital market response to marketing actions.

Design-based thinking elevates event studies from description to identification. Pre-treatment coefficients show whether \index{parallel trends}parallel trends is plausible, and post-treatment coefficients trace dynamics. Plots communicate the causal narrative at a glance and help stakeholders judge credibility and relevance.

\textbf{Caveat on pre-trend tests.} \index{pre-trend test}Pre-trend tests have low power: failing to reject the null that pre-treatment coefficients are zero does not prove that parallel trends holds. Pre-treatment data may be too noisy, the pre-treatment window too short, or the sample too small to detect violations. A non-significant pre-trend test provides supportive but not definitive evidence. Rambachan--Roth sensitivity analysis (Section~\ref{sec:event-diagnostics}) formalises how conclusions change if parallel trends is violated by a bounded amount.

As discussed in Chapter~\ref{ch:did} (Sections~\ref{sec:twfe-pitfalls}, \ref{sec:modern-estimators}, and \ref{sec:event-dynamics}), avoid using already-treated units as controls under staggered adoption and rely on heterogeneity-robust estimators instead. Here we focus on event-time specification, diagnostics, and interpretation. See Chapter~\ref{ch:did} for DiD estimands and TWFE pitfalls.

We develop the event-study framework for practical use in marketing panels. We define event-time estimands and aggregations, specify lead--lag regressions (normalisation, binning, windows), and estimate under staggered adoption with heterogeneity-robust methods. We state assumptions and diagnostics, give plotting and inference guidance, and cover extensions to continuous treatment and interference.

