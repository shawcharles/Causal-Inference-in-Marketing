\section{Motivation and Setup}
\label{sec:factor-motivation}

Factor models provide a generative framework for understanding how panel outcomes evolve over time and across units. Rather than assuming that units follow parallel trends or that control units can be reweighted to match treated units exactly, factor models posit that outcomes are driven by a small number of common time-varying shocks (\index{latent factors}factors). These factors affect different units with heterogeneous intensities (\index{factor loadings}loadings). This perspective explains patterns of co-movement across markets, stores, products, or customers. It motivates estimation methods that recover counterfactuals by imputing the unobserved outcomes for treated units using the estimated factor structure.

The factor model view is particularly natural in marketing panels. Regional sales co-move because they respond to national macroeconomic conditions, seasonal patterns, and industry-wide trends. However, the sensitivity to these shocks varies across regions due to differences in demographics, competitive intensity, or retail infrastructure. Store-level revenue exhibits common patterns driven by holidays, weather, and category-wide demand shifts, yet stores differ in their exposure based on format, size, and location. Factor models formalise these intuitions by decomposing outcomes into common shocks and heterogeneous loadings, providing a parsimonious representation of high-dimensional panel data. For single-unit SC designs see Chapter~\ref{ch:sc}; for hybrids and staggered adoption see Chapter~\ref{ch:generalized-sc}.

\subsection*{Advantages Over Parallel Trends and Synthetic Control}

The key advantage of factor models over parallel trends or synthetic control is flexibility in modelling how common shocks affect units.

Parallel trends, the foundation of difference-in-differences methods (Chapter~\ref{ch:did}), requires that treated and control units follow parallel trajectories in the absence of treatment. This implies that time-specific shocks affect all units identically---an additive time fixed effect $\gamma_t$ that is common to all units. This assumption fails when units differ in their sensitivity to common shocks (for example, when a recession affects urban stores more than rural stores).

Synthetic control (Chapter~\ref{ch:sc}) constructs a counterfactual by reweighting control units to match the treated unit's pre-treatment trajectory. However, it imposes convexity constraints on the weights (weights must be non-negative and sum to one) and requires that the treated unit lies within the convex hull of the control units. When the treated unit is an outlier---larger, more urban, or otherwise different from all control units---synthetic control cannot match it well.

Factor models relax both restrictions. They allow time shocks to affect units with heterogeneous intensities through interactive fixed effects (the product $\lambda_i' f_t$) rather than additive fixed effects ($\gamma_t$). They approximate the treated unit's outcomes using freely estimated loadings without convexity constraints. The treated unit need not lie within the convex hull of controls; instead, its loading vector $\lambda_i$ is estimated from the pre-treatment data.

\subsection*{The Cost of Flexibility: Low-Rank Structure}

The cost of this flexibility is an additional structural assumption. Factor models assume that the $N \times T$ outcome matrix admits a low-rank representation: it can be approximated by a product of an $N \times R$ loading matrix $\Lambda$ and an $R \times T$ factor matrix $F'$, where the rank $R$ is small relative to both $N$ and $T$. Formally, this means that most of the variation in outcomes is explained by a small number of common factors.

The low-rank assumption is an empirical regularity rather than an economic principle. It can be assessed through diagnostic tests such as scree plots (plotting the eigenvalues of the outcome matrix), eigenvalue ratios (comparing the $r$-th to the $(r+1)$-th eigenvalue), and information criteria that penalise model complexity. Section~\ref{sec:factor-ife} discusses rank selection in detail.

When the low-rank structure is plausible---for example, when a small number of macroeconomic shocks, seasonal patterns, and category trends drive most of the variation in outcomes---factor models provide accurate counterfactuals and efficient estimates. When the low-rank structure is weak---for example, when outcomes are driven by many idiosyncratic unit-time shocks with little common structure---factor models may overfit the pre-treatment data and extrapolate poorly to the post-treatment period. In such cases, the simpler parallel trends assumption may be preferable if it is plausible.

\subsection*{Connection to the Potential Outcomes Framework}

Connecting to the potential outcomes framework introduced in Chapter~\ref{ch:frameworks} and grounded in the foundational work of \citet{rubin1974estimating,imbens2015causal}, factor models provide a model for untreated potential outcomes $Y_{it}(0)$. The most general specification is the \index{interactive fixed effects}interactive fixed effects (IFE) model:
\[
Y_{it}(0) = \alpha_i + \gamma_t + \lambda_i' f_t + \varepsilon_{it},
\]
where $\alpha_i$ is a unit fixed effect capturing time-invariant heterogeneity, $\gamma_t$ is a time fixed effect capturing shocks common to all units, $\lambda_i \in \mathbb{R}^R$ is the loading vector for unit $i$, $f_t \in \mathbb{R}^R$ is the factor vector for period $t$, and $\varepsilon_{it}$ is an idiosyncratic error with mean zero. The interactive term $\lambda_i' f_t$ captures unit-specific responses to common time-varying shocks.

Special cases nest familiar models. When $R = 0$ (no interactive effects), the model reduces to the two-way fixed effects model underlying difference-in-differences. When $\alpha_i = \gamma_t = 0$, the model is a pure factor model. For treatment effect estimation, the counterfactual for a treated unit $i$ in post-treatment period $t$ is imputed as $\hat{\alpha}_i + \hat{\gamma}_t + \hat{\lambda}_i' \hat{f}_t$, and the treatment effect is the difference between the observed outcome $Y_{it}$ and this imputed counterfactual.

\subsection*{Connection to Matrix Completion}

Factor models are closely related to matrix completion methods. Viewed as a matrix, the panel of untreated outcomes $\{Y_{it}(0)\}$ has missing entries: the treated cells (unit-time combinations where treatment was applied). \index{nuclear norm}Nuclear-norm regularisation recovers the low-rank structure. The factor model $Y_{it}(0) = \lambda_i' f_t + \varepsilon_{it}$ implies that the underlying signal matrix $\Lambda F'$ is low-rank. Matrix completion methods recover this low-rank matrix from the observed (control) entries and use it to impute the missing (treated) entries.

This perspective is valuable because it connects causal panel methods to the broader literature on low-rank matrix estimation, including nuclear-norm regularisation, singular value decomposition, and soft-thresholding. It also clarifies when imputation is feasible: the observed entries must provide enough information to identify the low-rank structure. If treated units or treated periods are too different from control observations, the imputation may be unreliable. Section~\ref{sec:factor-matrix} develops the matrix completion perspective in detail.

\subsection*{Unification with Synthetic Control and SDID}

The framework developed by \citet{arkhangelsky2024causal} situates factor models within the modern panel data literature, clarifying their connection to synthetic control, difference-in-differences, and hybrid methods (Chapter~\ref{ch:generalized-sc}).

The relationship is most transparent when expressed in terms of how each method constructs the counterfactual for a treated unit. Difference-in-differences estimates the counterfactual as $\hat{Y}_{it}(0) = Y_{i,\text{pre}} + (\bar{Y}_{\text{control},t} - \bar{Y}_{\text{control},\text{pre}})$, effectively assuming that all units share the same loading ($\lambda_i = \lambda$ for all $i$)---a rank-one factor model. Synthetic control estimates the counterfactual as $\hat{Y}_{it}(0) = \sum_j w_j Y_{jt}$, where the weights $w_j$ are chosen to match pre-treatment outcomes; this is equivalent to assuming that the treated unit's loading is a convex combination of control loadings ($\lambda_1 = \sum_j w_j \lambda_j$ with $w_j \geq 0$, $\sum_j w_j = 1$). Factor models estimate the counterfactual as $\hat{Y}_{it}(0) = \hat{\lambda}_i' \hat{f}_t$, where the loading $\lambda_i$ is estimated freely without convexity constraints.

This unification clarifies when each method is preferable. If the treated unit is similar to controls and lies within their convex hull, synthetic control is appropriate. If all units share similar loadings (homogeneous sensitivity to shocks), difference-in-differences is appropriate. If the treated unit is an outlier with different loadings, factor models are necessary. Hybrid methods (Chapter~\ref{ch:generalized-sc}) combine these approaches through augmentation or regularisation.

\subsection*{Chapter Outline}

This chapter develops factor models and matrix completion methods in detail, with a focus on practical implementation in marketing panels. The interactive fixed effects (IFE) model is presented first, including identification, rank selection, and estimation via principal components and iterative procedures. The matrix completion perspective follows, emphasising nuclear-norm regularisation and the role of missingness patterns in identifying the factor structure. Formal identification assumptions are articulated using Assumption environments to clarify what conditions are necessary for valid causal inference. Connections to synthetic control and SDID are mapped explicitly, showing how these methods emerge as special cases or approximations of factor models. Guidance on tuning (rank selection, regularisation parameters) and implementation is provided, along with inference procedures adapted to factor models. Diagnostic workflows help practitioners assess whether the low-rank assumption is plausible and whether the factor model provides a credible counterfactual. Marketing applications illustrate how factor models handle the complex data structures common in marketing panels. A workflow checklist concludes the chapter. Together, these sections equip practitioners to apply factor models and matrix methods to generate credible causal evidence in complex marketing data structures.
