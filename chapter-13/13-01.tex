
\section{Motivation and Setup}
\label{sec:hd-motivation}

Modern marketing panels confront practitioners with an abundance of potential confounders. A retailer estimating a promotion's effect on sales might observe hundreds of store characteristics, market conditions, competitor actions, and platform signals. The covariate dimension $p$ can easily exceed the effective sample size, and a naïve regression that includes all covariates produces unstable estimates, multicollinearity, and overfitting. This undermines both the precision and credibility of causal inference.

Regularisation offers a principled solution. By shrinking or nullifying the coefficients of many covariates, these estimators retain only the most predictive variables. Lasso (an L1 penalty) encourages sparsity, performing variable selection by setting many coefficients to exactly zero. Elastic net (a mix of L1 and L2 penalties) balances sparsity with stability, allowing correlated covariates to be selected together. Group lasso penalises entire groups of covariates, enabling structured selection (for example, all lags of a variable). These methods allow us to control for confounding flexibly without overfitting, preserving valid causal inference even when the number of covariates $p$ is large.

The challenge is that regularisation, which is optimised for prediction, does not automatically respect the logic of causal identification. As \citet{breiman2001statistical} emphasised, prediction and identification pursue different goals. Prediction seeks to minimise forecast error, while identification aims to isolate a treatment effect by controlling for confounders without introducing new biases. A naïve application of lasso might omit important confounders or, conversely, include variables that introduce bias, such as colliders or mediators. Regularisation must be disciplined by the study's design to ensure it serves causal inference.

The connection to potential outcomes and identification, articulated in Chapter~\ref{ch:frameworks}, clarifies what regularisation accomplishes. Regularisation does not relax the identification assumptions formalised there—unconfoundedness, overlap, and SUTVA. Instead, it provides a data-driven method for selecting the conditioning set when theory does not uniquely specify which covariates are confounders. The goal is to approximate the sufficient conditioning set—the covariates that block all backdoor paths between treatment and outcome—using finite data, without overfitting. Regularisation succeeds when the true confounders are approximately sparse (only a few of the $p$ covariates matter), when the sample size is large enough relative to the sparsity level, and when dependence is accounted for in penalty choice and inference.

The design-based perspective emphasised by \citet{angrist2010credibility} provides a complementary lens. Difference-in-differences (Chapter~\ref{ch:did}), event studies (Chapter~\ref{ch:event}), and synthetic control methods (Chapters~\ref{ch:sc} and~\ref{ch:generalized-sc}) leverage panel structure to control for unobserved heterogeneity without strong parametric assumptions. Regularisation complements these designs by enabling richer covariate adjustment—for example, augmenting DiD with lasso-selected controls—while respecting the design's identifying variation. The key discipline is to avoid selecting controls that conflict with identification, such as post-treatment covariates or colliders, and to report transparently which covariates are selected and how estimates vary with penalty choice.

Positioning regularisation relative to factor models (Chapter~\ref{ch:factor}) and double machine learning (Chapter~\ref{ch:ml-nuisance}) clarifies the trade-offs. Factor models capture common shocks with heterogeneous loadings. Regularisation can select additional unit-specific controls after partialling out the factor structure, improving precision. DML uses orthogonalisation and cross-fitting to deliver robust causal estimates even when using flexible ML to model nuisance functions. Regularisation is a key tool within the DML framework for estimating those nuisance functions. In all these cases, regularisation is a powerful tool for selecting covariates in a way that respects and enhances a design-based identification strategy.

Marketing settings motivate regularisation through concrete empirical patterns. Consider a digital advertiser estimating the effect of display advertising on conversions using a panel of 500 DMAs observed over 52 weeks. The advertiser observes 200 covariates per DMA-week: demographics (age, income, education, household composition, employment, housing), competitive activity (ad spend by 20 competitors across 5 channels), seasonality (week-of-year dummies, holiday indicators, weather), search trends (Google Trends indices for 30 keywords), social media engagement (Twitter mentions, Facebook likes, Instagram impressions), website metrics (sessions, page views, bounce rates), and lagged outcomes (conversions in prior weeks). The covariate dimension $p = 200$ exceeds the number of DMAs ($N = 500$) and is comparable to the number of weeks ($T = 52$). A naïve regression including all 200 covariates produces unstable estimates (standard errors larger than coefficients), multicollinearity warnings (variance inflation factors exceeding 10), and overfitting (perfect fit in-sample but poor out-of-sample prediction). Regularisation via lasso selects 25 covariates (demographics, competitor ad spend, seasonality, and search trends) that predict conversions strongly, producing a parsimonious model with stable coefficients and interpretable results. Double selection (selecting from both the outcome and treatment models) ensures that confounders are retained even if they do not predict outcomes strongly, reducing omitted-variable bias. The result is a treatment effect estimate that is precise (narrow confidence intervals), credible (robust to penalty choice and specification), and interpretable (the selected covariates align with domain knowledge about drivers of conversions).

The remainder of this chapter proceeds as follows. We formalise high-dimensional panel models (Section~\ref{sec:hd-panels}), present regularisation methods and penalty choice under clustering (Section~\ref{sec:hd-methods}), develop double selection and post-selection inference (Sections~\ref{sec:hd-selection}–\ref{sec:hd-postselection}), and show integration with DiD and event-study designs (Section~\ref{sec:hd-did}). Later sections cover identification assumptions, tuning, diagnostics, and a practical workflow checklist.
