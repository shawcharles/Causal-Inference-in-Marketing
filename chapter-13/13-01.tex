
\section{Motivation and Setup}
\label{sec:hd-motivation}

Modern marketing panels confront practitioners with an abundance of potential confounders. A retailer estimating a promotion's effect on sales might observe hundreds of store characteristics, market conditions, competitor actions, and platform signals. The covariate dimension $p$ can easily exceed the effective sample size, and a naïve regression that includes all covariates produces unstable estimates, multicollinearity, and overfitting. This undermines both the precision and credibility of causal inference.

Regularisation offers a principled solution. By shrinking or nullifying the coefficients of many covariates, these estimators retain only the most predictive variables. Lasso (an L1 penalty) encourages sparsity, performing variable selection by setting many coefficients to exactly zero. Elastic net (a mix of L1 and L2 penalties) balances sparsity with stability, allowing correlated covariates to be selected together. Group lasso penalises entire groups of covariates, enabling structured selection (for example, all lags of a variable). These methods allow us to control for confounding flexibly without overfitting, preserving valid causal inference even when the number of covariates $p$ is large.

The challenge is that regularisation, which is optimised for prediction, does not automatically respect the logic of causal identification. As \citet{breiman2001statistical} emphasised, prediction and identification pursue different goals. Prediction seeks to minimise forecast error, while identification aims to isolate a treatment effect by controlling for confounders without introducing new biases. A naïve application of lasso might omit important confounders or, conversely, include variables that introduce bias, such as colliders or mediators. Regularisation must be disciplined by the study's design to ensure it serves causal inference.

The connection to potential outcomes and identification, articulated in Chapter~\ref{ch:frameworks} and by \citet{pearl2009causality}, clarifies what regularisation accomplishes. The potential outcomes framework posits that each unit has potential outcomes under each treatment level, and that causal effects are contrasts between potential outcomes. Identification requires assumptions (unconfoundedness, overlap, SUTVA) ensuring that treatment assignment is as good as random conditional on observables. Regularisation does not relax these identification assumptions. Instead, regularisation provides a data-driven method for selecting the conditioning set (the controls included in the regression or propensity score model) when theory does not uniquely specify which covariates are confounders. The goal is to approximate the oracle conditioning set (the minimal set of covariates that achieves conditional independence of treatment and potential outcomes) using finite data, without overfitting. Regularisation succeeds when the oracle set is approximately sparse (only a few of the $p$ covariates are true confounders), when the sample size is large enough relative to the sparsity level, and when dependence is accounted for in penalty choice and inference.

The design-based perspective emphasised by \citet{angrist2010credibility} provides a complementary lens. Design-based inference prioritises transparency, robustness to misspecification, and alignment with the intervention's design. Difference-in-differences (Chapter~\ref{ch:did}), event studies (Chapter~\ref{ch:event}), and synthetic control methods (Chapters~\ref{ch:sc} and~\ref{ch:generalized-sc}) estimate treatment effects without imposing strong parametric assumptions, leveraging the panel structure to control for unobserved heterogeneity. Regularisation complements these methods by enabling richer covariate adjustment (for example, augmenting DiD with high-dimensional controls selected by lasso) without abandoning the design-based logic. The key is to respect the design's identifying variation (for example, within-cohort, across-time variation in staggered DiD) and to avoid selecting controls that conflict with identification (for example, post-treatment covariates, colliders, or mediators). Transparent reporting of which covariates are selected, why they are included, and how estimates vary with penalty choice builds confidence that regularisation serves identification rather than obscuring it.

Positioning regularisation relative to factor models (Chapter~\ref{ch:factor}) and double machine learning (Chapter~\ref{ch:ml-nuisance}) clarifies the trade-offs. Factor models capture common shocks with heterogeneous loadings. Regularisation can select additional unit-specific controls after partialling out the factor structure, improving precision. DML uses orthogonalisation and cross-fitting to deliver robust causal estimates even when using flexible ML to model nuisance functions. Regularisation is a key tool within the DML framework for estimating those nuisance functions. In all these cases, regularisation is a powerful tool for selecting covariates in a way that respects and enhances a design-based identification strategy.

Marketing settings motivate regularisation through concrete empirical patterns. Consider a digital advertiser estimating the effect of display advertising on conversions using a panel of 500 DMAs observed over 52 weeks. The advertiser observes 200 covariates per DMA-week: demographics (age, income, education, household composition, employment, housing), competitive activity (ad spend by 20 competitors across 5 channels), seasonality (week-of-year dummies, holiday indicators, weather), search trends (Google Trends indices for 30 keywords), social media engagement (Twitter mentions, Facebook likes, Instagram impressions), website metrics (sessions, page views, bounce rates), and lagged outcomes (conversions in prior weeks). The covariate dimension $p = 200$ exceeds the number of DMAs ($N = 500$) and is comparable to the number of weeks ($T = 52$). A naïve regression including all 200 covariates produces unstable estimates (standard errors larger than coefficients), multicollinearity warnings (variance inflation factors exceeding 10), and overfitting (perfect fit in-sample but poor out-of-sample prediction). Regularisation via lasso selects 25 covariates (demographics, competitor ad spend, seasonality, and search trends) that predict conversions strongly, producing a parsimonious model with stable coefficients and interpretable results. Double selection (selecting from both the outcome and treatment models) ensures that confounders are retained even if they do not predict outcomes strongly, reducing omitted-variable bias. The result is a treatment effect estimate that is precise (narrow confidence intervals), credible (robust to penalty choice and specification), and interpretable (the selected covariates align with domain knowledge about drivers of conversions).

This chapter develops regularisation methods for panel causal inference in detail, with a focus on practical implementation in marketing settings. Section~\ref{sec:hd-panels} formalises models with high-dimensional controls, dependence structures, and the role of fixed effects and latent factors. Section~\ref{sec:hd-methods} presents lasso, elastic net, group lasso, and penalty choice under clustering. Section~\ref{sec:hd-selection} develops variable selection for causal targets, including double selection and orthogonalised ML with selection. Section~\ref{sec:hd-postselection} covers post-selection and debiased inference with cluster-robust uncertainty. Section~\ref{sec:hd-did} shows integration with DiD and event-study designs. Section~\ref{sec:hd-assumptions} articulates identification assumptions using formal Assumption environments. Section~\ref{sec:hd-tuning} provides guidance on tuning and implementation. Section~\ref{sec:hd-diagnostics} outlines diagnostic workflows. Section~\ref{sec:hd-inference} covers inference procedures. Section~\ref{sec:hd-marketing} illustrates applications in marketing. Section~\ref{sec:hd-workflow} provides a workflow checklist. Together, these sections equip practitioners to manage high-dimensional controls in panel causal inference transparently and credibly.
