\section{Event-Study Specifications and Dynamics}
\label{sec:event-dynamics}

Event-study specifications extend DiD logic to estimate treatment effects as a function of event time $k$, the number of periods since treatment adoption. The specification includes indicators for each event time, both pre-treatment (leads, $k < 0$) and post-treatment (lags, $k \geq 0$), and estimates a separate coefficient for each event time. The resulting sequence of coefficients traces the dynamic evolution of the treatment effect. It provides evidence on anticipation (non-zero leads), immediate effects (the coefficient at $k = 0$), and long-run effects (coefficients at large $k$).

\subsection*{Event-Study Specification}

The event-study regression takes the form
\[
Y_{it} = \alpha_i + \lambda_t + \sum_{k \neq -1} \theta_k \mathbb{I}\{t - G_i = k\} + \varepsilon_{it},
\]
where $\mathbb{I}\{t - G_i = k\}$ is an indicator that equals one if unit $i$ is at event time $k$ in period $t$, and the reference period is $k = -1$ (the period immediately before treatment adoption). The coefficients $\{\theta_k\}$ estimate the treatment effect at each event time relative to the reference period. By convention, $\theta_{-1}$ is normalised to zero (the reference period). All coefficients are therefore interpreted as differences from the outcome level in period $k = -1$. Under homogeneous treatment effects and valid identification, these coefficients coincide with the event-time effects $\theta_k$ defined in Section~\ref{sec:staggered-estimands}, but under heterogeneity they can diverge, as discussed below.

This normalisation assumes that any anticipation effects have not yet materialised by $k = -1$. If anticipation is already present at $k = -1$---for example, if customers have already begun changing behaviour in response to an announced programme---then $\theta_{-1}$ is not a clean baseline. The post-treatment coefficients would then understate the true treatment effect relative to a world with no anticipation. When anticipation is suspected, consider normalising to an earlier period (for example, $k = -2$ or $k = -3$) or to the average of distant pre-treatment periods.

\paragraph{Caution: TWFE Event-Study Contamination} The specification above is a TWFE-style event study and inherits the negative weighting problem under heterogeneous treatment effects discussed in Section~\ref{sec:twfe-pitfalls}. When effects vary across cohorts or over time, the TWFE event-study coefficients confound true dynamics with contamination from already-treated units serving as implicit controls. For clean identification of event-time effects, use Sun--Abraham's interaction-weighted estimator (which saturates the model with cohort-by-event-time interactions) or Callaway--Sant'Anna's event-time aggregation introduced in Section~\ref{sec:modern-estimators} (which estimates separate $\tau(g, g+k)$ for each cohort and then aggregates with transparent weights). These modern approaches produce event-study plots that reflect true dynamics rather than artefacts of heterogeneity.

\subsection*{Pre-Trends and Anticipation}

Pre-treatment leads ($k < -1$) test for pre-trends and anticipation. If parallel trends holds and there is no anticipation, pre-treatment coefficients should be near zero and statistically insignificant. Non-zero pre-treatment coefficients signal that treated units were on a different trajectory than controls even before treatment, violating parallel trends.

A word of caution: pre-trend tests have low power against many plausible violations \citep{roth2022pretest}. Passing a pre-trend test---observing flat, near-zero coefficients for $k < 0$---does not guarantee that parallel trends holds in the post-treatment period. The test provides supportive evidence, not proof. Substantive arguments about the assignment mechanism remain essential.

A pattern of pre-treatment coefficients that trend toward the post-treatment effect suggests anticipation: units respond to expected future treatment by altering behaviour in advance. Anticipation can be negative or positive. Negative anticipation occurs when customers delay purchases to qualify for future rewards (producing negative pre-treatment coefficients that grow in magnitude as the launch approaches). Positive anticipation occurs when customers accelerate purchases before an expected price increase, or when firms ramp up advertising before a product launch (producing positive pre-treatment coefficients). The sign and pattern of pre-treatment coefficients, combined with institutional knowledge about what units could have anticipated, helps distinguish anticipation from differential pre-trends, complementing the no-anticipation discussion in Section~\ref{sec:staggered-identification}.

\subsection*{Dynamic Effects}

Post-treatment lags ($k \geq 0$) trace the dynamic response. If the effect is immediate and constant, all post-treatment coefficients should be roughly equal. If the effect grows over time---as might occur with habit formation, learning, or network effects---then post-treatment coefficients increase with $k$. If the effect decays---as might occur with a temporary promotion or a one-time advertising campaign---then post-treatment coefficients decrease with $k$. The sequence $\{\theta_k\}_{k=0}^{K}$ provides a reduced-form estimate of the dynamic response without imposing parametric restrictions on the lag structure.

\paragraph{Worked Example: Interpreting Event-Study Coefficients} Consider a loyalty programme rollout with estimated coefficients and standard errors: $\hat{\theta}_{-3} = 0.8$ (SE = 1.2), $\hat{\theta}_{-2} = 0.4$ (SE = 1.0), $\hat{\theta}_{-1} = 0$ (reference), $\hat{\theta}_0 = 5.2$ (SE = 1.1), $\hat{\theta}_1 = 7.1$ (SE = 1.3), $\hat{\theta}_2 = 8.3$ (SE = 1.4), $\hat{\theta}_3 = 8.1$ (SE = 1.5), all in £000s of quarterly sales. The pre-treatment coefficients are statistically indistinguishable from zero: the 95\% confidence intervals for $\hat{\theta}_{-3}$ and $\hat{\theta}_{-2}$ include zero (approximately $[-1.6, 3.2]$ and $[-1.6, 2.4]$ respectively). This supports parallel trends---treated and control stores followed similar trajectories before the programme launched. The discrete jump at $k = 0$ reveals an immediate effect of £5,200 in incremental quarterly sales. The rising pattern from $k = 0$ to $k = 2$ ($5.2 \to 7.1 \to 8.3$) indicates growing effects, consistent with habit formation as customers accumulate points and increase visit frequency. The levelling at $k = 3$ ($8.1 \approx 8.3$) suggests the effect has reached a steady state. This pattern---flat pre-period, discrete jump, growth, then stabilisation---is characteristic of interventions that build customer engagement over time.

\subsection*{Binning and Reference Windows}

Binning choices determine how event times are grouped when the number of event times is large relative to the sample size. If the panel spans many periods and if some cohorts adopt treatment early (creating many post-treatment observations), estimating a separate coefficient for each $k$ can be impractical due to sparse data at large $k$. Binning groups adjacent event times into intervals---for example, $k \in \{0\}$, $k \in \{1, 2\}$, $k \in \{3, 4, 5\}$, $k \geq 6$---and estimates a single coefficient for each bin. The trade-off is between resolution (finer bins provide more detail about the dynamic profile) and precision (coarser bins pool more observations and reduce standard errors). A useful rule of thumb: aim for at least 50--100 observations per bin, or at least 10 treated units per bin, whichever is more restrictive. Report the binning scheme transparently and check robustness to alternative binning choices.

Reference window choices determine which event time is normalised to zero. The convention is to normalise $k = -1$, but other choices are possible. If no anticipation is expected and if the goal is to estimate the effect relative to the average of all pre-treatment periods, the reference can be the average of $k < 0$. If the goal is to estimate the change from period $k = -2$ to $k = 0$, the reference can be $k = -2$. The choice affects the interpretation of coefficients but not the differences between coefficients (which estimate treatment effect contrasts and are invariant to the reference choice). Transparency about the reference window and robustness checks using alternative references ensure that conclusions are not artefacts of the normalisation.

\paragraph{Endpoint Binning Caveat} When binning distant event times into a single coefficient (for example, $k \geq 6$), the estimate averages effects across different treatment durations. If effects are still evolving at large $k$---as occurs with habit formation, learning, or competitive adjustment---the binned coefficient obscures the dynamic trajectory. A flat binned coefficient at $k \geq 6$ might mask continued growth from $k = 6$ to $k = 10$. Report the binning cutoff explicitly, check sensitivity to alternative cutoffs (for example, $k \geq 4$ vs $k \geq 8$), and interpret binned coefficients as lower bounds on long-run effects when dynamics are likely to persist.

\subsection*{Interpretation and Diagnostics}

Interpretation of event-study plots requires care. A plot of $\theta_k$ against $k$ visualises the treatment effect trajectory, and statistical inference (confidence intervals around each $\theta_k$) assesses whether effects are distinguishable from zero. Pre-trend patterns that show flat, near-zero coefficients for $k < 0$ followed by a discrete jump at $k = 0$ provide strong support for parallel trends and for a causal interpretation. In practice, this idealised pattern is rare: real event-study plots often show noisy pre-trends, gradual ramp-ups, or delayed effects. Judgement is required to assess whether deviations from the ideal are substantively meaningful or merely noise.

Pre-trend patterns that show drifts or trends for $k < 0$ raise concerns about parallel trends. When pre-trends fail, several alternatives are available: condition on covariates to restore conditional parallel trends, use factor models that accommodate differential trends (Chapter~\ref{ch:factor}), or conduct sensitivity analysis to bound the bias from pre-trend violations (Chapter~\ref{ch:design-diagnostics}). Simply proceeding with the analysis while ignoring pre-trend violations is not acceptable.

Beyond visual inspection, a joint hypothesis test provides a formal complement. Test $H_0: \theta_{-K} = \theta_{-K+1} = \cdots = \theta_{-2} = 0$ using a Wald test with cluster-robust standard errors (a standard F-test assumes homoskedasticity and is inappropriate when errors are clustered). Rejection suggests pre-trends or anticipation; failure to reject is consistent with parallel trends but does not prove it (given the low power of such tests). Report both the visual evidence and the joint test.

Figure~\ref{fig:event-study-plot} illustrates a typical event-study plot showing pre-treatment coefficients, the treatment effect at adoption, and the dynamic evolution of effects over time.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{images/event_study_plot.pdf}
\caption{Event-Study Plot: Pre-Trends and Dynamic Effects}
\label{fig:event-study-plot}
\small\textit{A well-behaved event-study plot exhibits three features: (i) flat, near-zero coefficients for $k < 0$, supporting the parallel trends assumption; (ii) a discrete jump at $k = 0$, indicating an immediate treatment effect; and (iii) a clear post-treatment trajectory revealing dynamics---whether constant (flat), growing (habit formation, learning), or decaying (temporary promotion). Drifting pre-trends that slope upward or downward signal parallel trends violations. Non-zero coefficients at distant leads ($k = -2, -3, \ldots$) may indicate anticipation effects. The dashed horizontal line at zero and the vertical line at $k = 0$ provide visual reference. Confidence intervals should be reported; overlapping zero in the pre-period supports identification, while non-overlapping zero in the post-period indicates statistically significant effects.}
\end{figure}

Event-study specifications are closely related to distributed lag models (Chapter~\ref{ch:dynamics}), which parameterise the lag structure and estimate the effect of current and lagged treatments on current outcomes. Distributed lag models impose functional form assumptions on the decay or persistence of effects, enabling extrapolation beyond the observed event times and estimation of long-run multipliers, but they require stronger assumptions than the reduced-form event study. The trade-off is between flexibility (event studies impose minimal restrictions) and efficiency and interpretability (distributed lags provide parsimonious summaries and long-run estimates).

Marketing applications of event studies abound. A loyalty programme rollout with staggered adoption across stores over multiple quarters produces an event study with many cohorts and many event times, enabling detailed tracing of how programme effects evolve as customers accumulate points and develop habits. An advertising campaign with staggered launches across markets produces an event study that reveals whether effects peak immediately (as might occur with direct response advertising) or build over time (as might occur with brand-building campaigns). A pricing policy change implemented in waves across product categories produces an event study that traces competitive responses and demand adjustments over time. In each case, the event-study plot provides transparent evidence on dynamics, anticipation, and long-run effects, complementing the summary estimates produced by modern DiD estimators.

For plotting standards and diagnostics, see Chapter~\ref{ch:event}, Sections~\ref{sec:event-graphs} and \ref{sec:event-diagnostics}. Inference for event-time paths appears in Chapter~\ref{ch:event}, Section~\ref{sec:event-inference}. We now turn to inference for DiD estimators.
