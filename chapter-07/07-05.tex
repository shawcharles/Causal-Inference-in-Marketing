\section{Triply Robust Panel (TROP) Estimators}
\label{sec:hybrid-trop}

The synthetic control, augmented synthetic control, and synthetic difference-in-differences methods explored in the preceding sections each address limitations of pure parallel trends or pure weighting approaches. However, each method relies primarily on one or two mechanisms to construct valid counterfactuals. Standard synthetic control depends on finding a convex combination of donors that matches the treated unit's trajectory. Augmented synthetic control adds a regression adjustment to correct residual imbalances. SDID incorporates time weights to accommodate common time effects after reweighting. Each method achieves robustness within its framework, but performance can deteriorate when the primary identification mechanism fails. For example, SDID remains biased if weighted parallel trends does not hold, even if the time and unit reweighting is optimal.

A natural extension combines all three mechanisms simultaneously: unit weights, time weights, and flexible outcome modelling. The Triply RObust Panel (TROP) estimator, introduced by \citet{athey2025triply}, formalises this integration. TROP constructs counterfactuals by jointly learning unit weights (to balance treated and control groups), time weights (to discount less informative periods), and a low-rank factor structure (to capture interactive fixed effects beyond additive trends). The method achieves triple robustness within a factor model framework. The bias of the TROP estimator is the product of unit-level imbalance, time-level imbalance, and regression model misspecification. If any one of these three components is negligible, the bias vanishes. This provides stronger protection against assumption violations than methods that rely on fewer components.

The critical distinction is that TROP does not escape the need for structural assumptions about untreated potential outcomes. The method assumes a factor model structure that we state formally.

\begin{assumption}[Factor Model for Untreated Potential Outcomes]
\label{ass:trop-factor}
For all units $i$ and periods $t$:
\[
Y_{it}(0) = \alpha_i + \beta_t + \lambda_i' f_t + \varepsilon_{it}, \quad \mathbb{E}[\varepsilon_{it} \mid \mathbf{L}] = 0,
\]
where $\alpha_i$ are unit fixed effects, $\beta_t$ are time fixed effects, $\lambda_i \in \mathbb{R}^K$ is a unit-specific loading vector, $f_t \in \mathbb{R}^K$ is a time-specific factor vector, and $\varepsilon_{it}$ is idiosyncratic noise. The low-rank matrix $\mathbf{L}$ with elements $L_{it} = \lambda_i' f_t$ captures interactive fixed effects.
\end{assumption}

This factor model framework is more flexible than additive parallel trends (which DID assumes) but more restrictive than fully nonparametric models. Triple robustness operates within this framework. If the factor structure is correctly specified but unit weights are misspecified, TROP remains consistent provided time weights correctly align pre-treatment means. If unit weights are correct but the factor model is wrong, TROP remains consistent provided time weights balance residual trends. If both unit and time weights are correct but the factor rank is misspecified, TROP remains consistent because the weighting removes bias. This multiplicative bias structure provides insurance against partial model failures while maintaining transparent interpretability.

\subsection*{Clarifying Robustness and the Role of Factor Structure}

Understanding TROP's contribution requires clarity about what robustness means in different contexts. The term doubly robust has two distinct uses in the panel literature, and conflating them obscures what TROP achieves.

Traditional double robustness, exemplified by augmented synthetic control (ASCM), provides genuine insurance against misspecification. ASCM is consistent if either the weighting model correctly specifies the synthetic control or the regression model correctly captures residual imbalances. If the treated unit lies near but not within the donor convex hull, the synthetic control weights may be imperfect. The regression adjustment corrects the residual bias. Alternatively, if the regression model is misspecified but the weights achieve good balance, the weighting removes bias. This is double robustness in the traditional sense. The analyst need not know which component is correctly specified.

SDID's notion of double robustness is different. Arkhangelsky et al. show that SDID's bias is the product of unit-level imbalance (after reweighting) and time-level imbalance (after differencing). If either component is negligible, bias is small. However, this product structure operates within the additive separability assumption. SDID still requires that weighted parallel trends holds. Outcomes must decompose as $Y_{it}(0) = \alpha_i + \beta_t + \varepsilon_{it}$, where $\alpha_i$ are unit fixed effects, $\beta_t$ are time fixed effects, and errors are idiosyncratic. The time effects $\beta_t$ are uniform across units. If this additive structure fails because units respond heterogeneously to common shocks, SDID is biased. The unit and time weights balance means and reduce variance, but they do not eliminate bias when the outcome model is misspecified. This is double robustness within an additive framework, not insurance against model misspecification.

TROP replaces additive separability with a factor-structured model. Untreated potential outcomes decompose as
\[
Y_{it}(0) = \alpha_i + \beta_t + \lambda_i' f_t + \varepsilon_{it},
\]
where $\lambda_i$ is a unit-specific loading vector and $f_t$ is a time-varying factor vector. The low-rank matrix $\mathbf{L}_{it} = \lambda_i' f_t$ captures interactive fixed effects. Units load heterogeneously on common factors. The same time shock $f_t$ affects different units differently depending on their loadings $\lambda_i$. This accommodates three types of violations of additive parallel trends. First, units may have different slopes over time (unit-specific trends not captured by a single $\beta_t$). Second, units may respond heterogeneously to shocks (the same macroeconomic recession, seasonal event, or competitive pressure affects units with different intensities). Third, unit-by-time interactions may be strong (wealthy markets respond differently to holiday shopping patterns than budget markets, and these responses evolve over time).

A concrete example clarifies the distinction. Suppose a national recession occurs during the pre-treatment period, and the analyst is evaluating advertising effectiveness across designated market areas. Under additive parallel trends, all DMAs lose the same percentage of sales during the recession. This is implausible. Wealthy DMAs with discretionary spending may lose 10 per cent of sales. Industrial DMAs with manufacturing employment may lose 15 per cent. Budget DMAs where consumers trade down to cheaper alternatives may lose only 2 per cent. SDID reweights units to prioritise DMAs similar to the treated unit and differences out baseline levels. However, if the treated DMA is a wealthy market and the recession affects wealthy markets non-linearly over time, SDID's additive model misfits the data. TROP estimates a recession factor $f_t$ that captures the intensity of the recession at each time period. It estimates unit-specific loadings $\lambda_i^{\text{wealthy}} = -0.10$, $\lambda_i^{\text{industrial}} = -0.15$, $\lambda_i^{\text{budget}} = -0.02$. The counterfactual for the treated DMA is constructed as $\hat{Y}_{it}^{\text{TROP}}(0) = \hat{\alpha}_i + \hat{\beta}_t + \hat{\lambda}_i' \hat{f}_t$, where the factor loadings capture heterogeneous sensitivity to the recession. The same common shock produces different trajectories, and the factor structure models this explicitly.

Triple robustness operates within this factor framework. The bias in TROP is the product of unit-level imbalance (after reweighting), time-level imbalance (after differencing), and factor model error (approximation error in the low-rank decomposition). If any one component is negligible, bias vanishes. If unit weights perfectly balance treated and control groups, the factor model and time weights need not be correct. If time weights perfectly align pre-treatment means, the unit weights and factor model need not be correct. If the factor model perfectly captures the interactive structure, the weights need not be perfect. This provides stronger protection against partial model failures than methods that rely on fewer components, provided the underlying factor structure assumption holds. However, this protection is conditional on the factor structure existing. If outcomes do not admit a low-rank decomposition because unit-specific trends are idiosyncratic and heterogeneous, the factor model error is large. Triple robustness does not eliminate bias when the factor framework itself fails. The method replaces additive parallel trends with factor-structured parallel trends. It does not eliminate the need for structural assumptions.

The practical implication is that TROP is most valuable when outcomes co-move due to common shocks, but units differ in their sensitivity to those shocks. Marketing panels often exhibit this structure. Sales respond to seasonality, macroeconomic conditions, and competitive dynamics. However, the strength of these responses varies by market demographics, product categories, and competitive intensity. Factor models capture this heterogeneity naturally. TROP learns the factor structure and the weights jointly via cross-validation. If the data support a low-rank decomposition, TROP's triple robustness provides credible counterfactuals. If the data are idiosyncratic (no strong factor structure), cross-validation selects a large nuclear norm penalty, and TROP reduces to SDID. The method adapts to the data rather than imposing a rigid structure.

\subsection*{Estimator Definition and Optimisation}

TROP predicts the counterfactual outcome for treated unit $i$ in period $t$ by solving a weighted nuclear-norm-regularised regression. Let $W_{it} \in \{0, 1\}$ denote the treatment indicator for unit $i$ in period $t$, where $W_{it} = 1$ if unit $i$ receives treatment at or before period $t$ and zero otherwise. Let $\omega_j^{i,t}$ denote the weight assigned to control unit $j$ when constructing the counterfactual for $(i, t)$, and let $\theta_s^{i,t}$ denote the weight assigned to pre-treatment period $s$. The TROP estimator solves
\[
(\hat{\alpha}, \hat{\beta}, \hat{\mathbf{L}}) = \arg\min_{\alpha, \beta, \mathbf{L}} \sum_{j=1}^N \sum_{s=1}^T \theta_s^{i,t} \omega_j^{i,t} (1 - W_{js}) \left( Y_{js} - \alpha_j - \beta_s - L_{js} \right)^2 + \lambda_{nn} \| \mathbf{L} \|_*,
\]
where $\alpha_j$ are unit fixed effects, $\beta_s$ are time fixed effects, $\mathbf{L}$ is a low-rank matrix capturing interactive fixed effects, and $\lambda_{nn}$ is the nuclear norm penalty parameter. The nuclear norm $\| \mathbf{L} \|_*$ is the sum of singular values of $\mathbf{L}$, which encourages low-rank structure and serves as a convex surrogate for rank minimisation (Chapter~\ref{ch:factor}). The summation runs over untreated observations only, ensuring that the model is not contaminated by treated outcomes.

The counterfactual for treated unit $i$ in period $t$ is computed as
\[
\hat{Y}_{it}^{\text{TROP}}(0) = \hat{\alpha}_i + \hat{\beta}_t + \hat{L}_{it},
\]
and the treatment effect estimate is
\[
\hat{\tau}_{it}^{\text{TROP}} = Y_{it} - \hat{Y}_{it}^{\text{TROP}}(0) = Y_{it} - \hat{\alpha}_i - \hat{\beta}_t - \hat{L}_{it}.
\]
This formulation unifies existing methods as special cases. When $\lambda_{nn} = \infty$ (no factor structure) and $\omega_j = \theta_s = 1$ (uniform weights), TROP reduces to two-way fixed effects (TWFE) difference-in-differences. When $\omega_j = \theta_s = 1$ but $\lambda_{nn} < \infty$, TROP reduces to matrix completion (Chapter~\ref{ch:factor}). When $\lambda_{nn} = \infty$ and $\theta_s = 1$ but unit weights are data-driven, TROP reduces to synthetic control. When $\lambda_{nn} = \infty$ but both unit and time weights are data-driven, TROP reduces to SDID. The flexibility to nest these methods allows TROP to learn which components matter most for a given application.

\subsection*{Choice of Weights and Tuning Parameters}

The weights $\omega_j^{i,t}$ and $\theta_s^{i,t}$ are not arbitrary but are chosen to minimise imbalances between treated and control groups. For unit weights, \citet{athey2025triply} propose exponential decay based on the pre-treatment distance between units:
\[
\omega_j^{i,t}(\lambda_{\text{unit}}) = \exp\left( -\lambda_{\text{unit}} \cdot \text{dist}_{-t}^{\text{unit}}(j, i) \right),
\]
where the distance is the root mean squared difference in pre-treatment outcomes:
\[
\text{dist}_{-t}^{\text{unit}}(j, i) = \left( \frac{\sum_{s=1}^T \mathbf{1}\{s \neq t\} (1 - W_{is})(1 - W_{js})(Y_{is} - Y_{js})^2}{\sum_{s=1}^T \mathbf{1}\{s \neq t\} (1 - W_{is})(1 - W_{js})} \right)^{1/2}.
\]
Units that are far from the treated unit (large distance) receive low weight, while units that track the treated unit closely receive high weight. The decay rate $\lambda_{\text{unit}}$ controls the steepness of the weighting function. When $\lambda_{\text{unit}} = 0$, all units receive equal weight (standard matrix completion). When $\lambda_{\text{unit}} \to \infty$, only the nearest unit receives positive weight (nearest-neighbour matching).

For time weights, exponential decay based on temporal distance is used:
\[
\theta_s^{i,t}(\lambda_{\text{time}}) = \exp\left( -\lambda_{\text{time}} \cdot |t - s| \right),
\]
where $|t - s|$ is the number of periods separating $s$ from the treatment period $t$. Recent periods (small $|t - s|$) receive high weight, while distant periods receive low weight. When $\lambda_{\text{time}} = 0$, all periods receive equal weight (standard synthetic control or matrix completion). When $\lambda_{\text{time}} \to \infty$, only the immediately preceding period receives positive weight (first-difference specification).

The tuning parameters $(\lambda_{\text{unit}}, \lambda_{\text{time}}, \lambda_{nn})$ are chosen via leave-one-out cross-validation. The core idea is that if the TROP model correctly predicts untreated outcomes, then applying it to control units (treating them as if they were treated) should yield small prediction errors. For each control unit-period pair $(j, s)$ with $W_{js} = 0$, compute the pseudo treatment effect:
\[
\hat{\tau}_{js}^{\text{CV}}(\lambda) = \arg\min_\tau \min_{\alpha, \beta, \mathbf{L}} \sum_{j', s': W_{j's'} = 0} \omega_{j'}^{j,s}(\lambda) \theta_{s'}^{j,s}(\lambda) \left( Y_{j's'} - \alpha_{j'} - \beta_{s'} - L_{j's'} - \tau \cdot \mathbf{1}\{(j', s') = (j, s)\} \right)^2 + \lambda_{nn} \| \mathbf{L} \|_*.
\]
This estimates the treatment effect on control unit $(j, s)$ as if it were treated, using only other control observations. The cross-validation objective is
\[
Q(\lambda) = \sum_{i=1}^N \sum_{t=1}^T (1 - W_{it}) \left( \hat{\tau}_{it}^{\text{CV}}(\lambda) \right)^2.
\]
The optimal tuning parameters $\hat{\lambda} = (\hat{\lambda}_{\text{unit}}, \hat{\lambda}_{\text{time}}, \hat{\lambda}_{nn})$ minimise $Q(\lambda)$ over a discrete grid. This choice balances prediction accuracy (small cross-validation error) against model complexity (regularisation). The data-driven selection ensures that TROP adapts to the specific structure of the panel rather than imposing a priori assumptions about which components matter.

The cross-validation procedure effectively acts as a model selector. If the data are well-approximated by an additive model (no strong factor structure), the procedure will select a large $\lambda_{nn}$ to suppress the factor term, automatically reverting to a simpler estimator similar to SDID. If the data require interactive fixed effects, it will select a smaller $\lambda_{nn}$ to allow for a higher-rank approximation. Similarly, if recent periods are far more informative than distant past periods, it will select a large $\lambda_{\text{time}}$, giving the estimator a 'local' character. This adaptability allows TROP to tailor its complexity to the signal-to-noise ratio of the specific dataset.

\subsection*{Triple Robustness Property}

The defining theoretical property of TROP is its multiplicative bias structure. To state this precisely, we first present the estimator's four-cell representation, which clarifies why triple robustness emerges.

\paragraph{Four-Cell Representation.} For treated unit $N$ in period $T$, the TROP counterfactual can be written as:
\begin{equation}
\label{eq:trop-four-cell}
\hat{Y}_{NT}^{\text{TROP}}(0) = \hat{\mathbf{L}}_{NT} + \sum_{t \leq T_0} \theta_t (Y_{Nt} - \hat{\mathbf{L}}_{Nt}) + \sum_{j \leq N_0} \omega_j (Y_{jT} - \hat{\mathbf{L}}_{jT}) - \sum_{j \leq N_0} \sum_{t \leq T_0} \omega_j \theta_t (Y_{jt} - \hat{\mathbf{L}}_{jt}).
\end{equation}
This representation decomposes the counterfactual into four components: the regression prediction $\hat{\mathbf{L}}_{NT}$, a time-weighted correction using the treated unit's pre-treatment residuals, a unit-weighted correction using the control units' treatment-period residuals, and an interaction correction. The structure mirrors doubly robust estimation: if the regression model $\hat{\mathbf{L}}$ is correct, the residual corrections vanish; if the weights achieve perfect balance, the corrections remove any bias from regression misspecification.

\paragraph{Formal Bias Bound.} The following assumption on the regression adjustment is required for the formal result.

\begin{assumption}[Regression Adjustment Estimators]
\label{ass:trop-regression}
There exists a matrix $B \in \mathbb{R}^{K \times K}$ such that
\[
\mathbb{E}[\hat{\mathbf{L}} \mid \mathbf{L}] = \Gamma (\mathbb{I}_K + B) \Lambda',
\]
where $\Gamma$ and $\Lambda$ are the factor loadings and factors from Assumption~\ref{ass:trop-factor}, and $\mathbb{I}_K$ is the $K \times K$ identity matrix. The matrix $B$ captures bias from shrinkage, rank truncation, or misspecification.
\end{assumption}

This assumption is satisfied by common estimators including truncated SVD, nuclear-norm penalised least squares, and general singular-value shrinkage estimators under isotropic noise.

\begin{theorem}[Triple Robustness]
\label{thm:trop-triple}
Let Assumptions~\ref{ass:trop-factor} and~\ref{ass:trop-regression} hold. For fixed weights $\omega$ and $\theta$ (interpreted as probability limits), the conditional bias of the TROP estimator satisfies:
\[
\left| \mathbb{E}[\hat{\tau} - \tau \mid \mathbf{L}] \right| \leq \underbrace{\| \Delta^{\text{unit}}(\omega, \Gamma) \|_2}_{\text{Unit imbalance}} \times \underbrace{\| \Delta^{\text{time}}(\theta, \Lambda) \|_2}_{\text{Time imbalance}} \times \underbrace{\| B \|_*}_{\text{Regression error}},
\]
where $\Delta^{\text{unit}}(\omega, \Gamma) = \bar{\Gamma}_0(\omega) - \Gamma_N$ is the difference between the weighted average control loadings and the treated unit's loadings, $\Delta^{\text{time}}(\theta, \Lambda) = \bar{\Lambda}_0(\theta) - \Lambda_T$ is the difference between the weighted average pre-treatment factors and the treatment-period factors, and $\| B \|_*$ is the spectral norm of the regression bias matrix.
\end{theorem}

\begin{corollary}[Conditions for Unbiasedness]
\label{cor:trop-unbiased}
Under Assumptions~\ref{ass:trop-factor} and~\ref{ass:trop-regression}, the TROP estimator is unbiased if any one of the following holds:
\begin{enumerate}
\item \textbf{Unit balance:} $\sum_{j \leq N_0} \omega_j \Gamma_j = \Gamma_N$ (weighted control loadings equal treated loadings).
\item \textbf{Time balance:} $\sum_{t \leq T_0} \theta_t \Lambda_t = \Lambda_T$ (weighted pre-treatment factors equal treatment-period factors).
\item \textbf{Correct regression:} $B = \mathbf{0}$ (the regression adjustment is correctly specified).
\end{enumerate}
\end{corollary}

The product structure in Theorem~\ref{thm:trop-triple} is the source of triple robustness: only one of the three conditions needs to hold for bias to vanish.

The practical implication is insurance against partial model failures. If unit weights are poorly specified (the treated unit is far from any weighted combination of controls), but time weights and the factor model are correct, the bias remains small because the product includes a small time-level or model error term. If the factor model is misspecified (the true rank exceeds the estimated rank, or the nuclear norm penalty induces too much shrinkage), but unit and time weights align treated and control groups well, the bias remains small because the product includes small imbalance terms. If all three components are partially misspecified but none is severely wrong, the bias remains moderate because the product of three small terms is very small.

This contrasts with SDID, which achieves double robustness within its framework. SDID's bias depends on the product of unit imbalance and time imbalance, but it does not incorporate a flexible outcome model. If weighted parallel trends fails even after optimal reweighting, SDID is biased. TROP adds the factor model component, providing a third layer of protection. However, this protection operates within the factor model framework. If outcomes do not admit a low-rank decomposition (for example, if unit-specific trends are highly heterogeneous and not captured by a few factors), the factor model error term is large, and triple robustness does not eliminate bias.

\subsection*{Connection to Factor Models and Identification}

The TROP estimator is grounded in the factor model perspective developed in Chapter~\ref{ch:factor}. Untreated potential outcomes are assumed to decompose as
\[
Y_{it}(0) = \alpha_i + \beta_t + \lambda_i' f_t + \varepsilon_{it},
\]
where $\alpha_i$ and $\beta_t$ are unit and time fixed effects, $\lambda_i$ is a unit-specific loading vector, $f_t$ is a time-specific factor vector, and $\varepsilon_{it}$ is an idiosyncratic error. The low-rank matrix $\mathbf{L}$ approximates the interactive component $\lambda_i' f_t$. The nuclear norm penalty encourages parsimony, shrinking the rank of $\mathbf{L}$ toward the true factor rank.

Identification requires that this decomposition holds in both pre-treatment and post-treatment periods. The unit and time fixed effects absorb additive level shifts and common time trends. The low-rank component captures interactive patterns (heterogeneous responses to common shocks). The error term reflects idiosyncratic noise that is not systematically related to treatment. If this structure holds, the TROP counterfactual is unbiased. If the structure fails (for example, if post-treatment shocks introduce new factors not present in the pre-treatment period), the counterfactual is biased. Stability assumptions parallel those for ASCM (Section~\ref{sec:hybrid-ascm}) and SDID (Section~\ref{sec:hybrid-sdid}). The factor structure, the unit weights, and the time weights estimated from pre-treatment data must extrapolate to post-treatment periods.

The connection to SDID clarifies the role of TROP. SDID assumes additive separability (outcomes are sums of unit effects, time effects, and noise). TROP relaxes this to allow interactive effects (unit-specific responses to time-varying shocks). This flexibility accommodates marketing panels where units differ in their sensitivity to macro conditions, seasonality, or competitive dynamics. For example, stores in different regions may respond differently to national advertising campaigns, economic recessions, or holiday shopping patterns. SDID, which imposes uniform time effects, may misfit such patterns. TROP, which allows for heterogeneous loadings on time factors, can capture them. The cost is additional complexity (estimating the factor structure and tuning the nuclear norm penalty) and stronger structural assumptions (the low-rank decomposition must hold).

\subsection*{Empirical Performance and Benchmarking}

The empirical performance of TROP relative to existing methods is documented extensively in \citet{athey2025triply} using semi-synthetic simulations calibrated to real datasets. The simulations generate potential outcomes from rank-four factor models estimated on six widely studied panels: Current Population Survey (CPS) wage and employment data, Penn World Table (PWT) GDP data, Germany reunification, Basque terrorism, California smoking, and Mariel boatlift. Treatment is assigned either randomly or according to empirically observed assignment mechanisms (for example, minimum wage adoption patterns in CPS). True treatment effects are set to zero, allowing the authors to assess the root mean squared error (RMSE) of counterfactual predictions.

Across 21 specifications spanning these datasets, TROP outperforms all competitors (DID, SC, SDID, MC, and a Doudchenko-Imbens-Ferman-Pinto variant of SC) in 20 out of 21 cases. The performance gains are substantial. For the Basque GDP data with random treatment assignment, TROP achieves RMSE 9.11 times lower than DID and 4.55 times lower than SC. For the PWT democracy treatment, TROP achieves RMSE 7.85 times lower than DID and 1.59 times lower than SC. Even relative to SDID, which is itself a strong performer, TROP achieves RMSE reductions of 10 to 50 per cent in most specifications. The only case where TROP underperforms is the Boatlift dataset with the actual treated unit as the estimand, where SC achieves RMSE 24 per cent lower than TROP. This exception arises because the treated unit (Miami) is very well matched by a sparse synthetic control (a few similar labour markets), and the additional complexity of TROP introduces noise without improving fit.

The simulations reveal that the benefits of TROP are largest when interactive fixed effects are present (the factor component $\mathbf{L}$ explains substantial variation), when the number of treated units and periods is moderate (allowing sufficient data to estimate the factor structure), and when neither unit weights nor time weights alone suffice to balance treated and control groups. DID performs poorly when interactive effects violate parallel trends. SC performs poorly when the treated unit is outside the convex hull or when few pre-treatment periods are available. SDID performs poorly when weighted parallel trends still fails due to unmodelled factor structure. TROP, by combining all three components and learning their relative importance via cross-validation, adapts to the specific challenges of each dataset.

\subsection*{When to Use TROP versus SDID versus ASCM}

Practitioners face the question of when to prefer TROP over simpler alternatives. TROP is preferable when interactive fixed effects are suspected (outcomes co-move in ways that cannot be captured by additive unit and time effects), when the sample size is sufficient to estimate a low-rank model (at least 20 units and 20 periods), and when both unit-level and time-level heterogeneity are present. In such settings, TROP's flexibility and data-driven tuning provide substantial gains over methods that rely on fewer components.

SDID is preferable when the primary concern is differential trends across units and common shocks across time, and when the analyst believes that additive fixed effects (without interactive terms) suffice. SDID is simpler to implement, has fewer tuning parameters (only unit and time weights, without the nuclear norm penalty), and is more transparent (the weights have clear interpretations as balancing statistics). If the factor structure is weak (interactive effects explain little variation beyond fixed effects), SDID achieves nearly the same performance as TROP with less complexity. SDID also extends more naturally to settings with very small samples (fewer than 10 treated units or 10 periods), where estimating a low-rank model is infeasible.

ASCM is preferable when the treated unit is near but not within the donor convex hull, and when the analyst has strong prior beliefs about which covariates should enter the augmentation regression. ASCM allows for nonlinear or interaction terms in the regression, whereas TROP assumes a linear low-rank structure. ASCM is also more interpretable when the augmentation model has a clear substantive meaning (for example, adjusting for store size and demographics in a retail panel). TROP's factor loadings are often rotational artefacts without economic interpretation.

Standard synthetic control remains preferable when the treated unit is well within the convex hull, pre-treatment fit is tight, and the analyst prioritises simplicity and transparency. If the pre-treatment RMSPE for SC is already very small (indicating that the treated unit can be closely approximated by a weighted average of donors), adding time weights, factor structure, and cross-validation may introduce noise without improving fit. The Boatlift exception in \citet{athey2025triply} illustrates this point. Miami is well matched by a few similar cities, and SC achieves excellent fit. TROP's additional components add complexity without benefit.

A pragmatic workflow estimates multiple methods (SC, SDID, ASCM, TROP) and compares their pre-treatment fit, weight dispersion, and sensitivity to specification choices. If estimates converge across methods, conclusions are robust. If estimates diverge, the analyst should diagnose the source of disagreement. Does TROP achieve substantially better pre-treatment fit than SDID or ASCM? Do the cross-validation-selected tuning parameters imply that unit weights, time weights, or the factor structure dominate? Does the factor structure align with institutional knowledge about the data-generating process? Transparent reporting of these diagnostics, alongside estimates from multiple methods, builds a cumulative case for causal conclusions.

\subsection*{Implementation and Computational Considerations}

Implementing TROP requires solving a large convex optimisation problem. The nuclear norm penalty renders the objective function smooth and convex, allowing efficient solution via proximal gradient descent or alternating direction method of multipliers (ADMM). Software implementations are available in R (the \texttt{gsynth} package extends naturally to incorporate unit and time weights) and Python (the \texttt{cvxpy} library provides nuclear norm minimisation routines). Computational cost scales with the product $NT$ (number of unit-period pairs) and the number of singular values computed. For moderately sized panels (100 units, 50 periods), TROP can be estimated in seconds on a standard laptop. For very large panels (thousands of units or hundreds of periods), approximation methods (randomised SVD, sparse plus low-rank decompositions) accelerate computation.

Cross-validation over the three-dimensional grid $(\lambda_{\text{unit}}, \lambda_{\text{time}}, \lambda_{nn})$ is computationally intensive. A full grid search with 10 values per dimension requires 1,000 model fits. \citet{athey2025triply} recommend a staged approach. First, fix $\lambda_{\text{unit}} = 0$ and $\lambda_{nn} = \infty$ (reducing to a one-dimensional search over $\lambda_{\text{time}}$ for a SDID-type estimator). Select the optimal $\lambda_{\text{time}}$ via cross-validation. Second, fix $\lambda_{\text{time}}$ at the selected value and search over $\lambda_{\text{unit}}$ (tuning the unit weights). Third, fix both $\lambda_{\text{unit}}$ and $\lambda_{\text{time}}$ and search over $\lambda_{nn}$ (tuning the factor structure). This staged procedure reduces computational cost by a factor of 100 while typically identifying near-optimal tuning parameters. Alternatively, Bayesian optimisation or random search can explore the three-dimensional space more efficiently than full grid search.

\subsection*{Practical Considerations for Marketing Panels}

Marketing panels often exhibit features that make TROP particularly valuable. Sales, revenue, and customer behaviour co-move due to seasonality, macroeconomic conditions, and category-wide trends. However, the strength of co-movement varies across units. Stores in affluent neighbourhoods respond more strongly to economic downturns than stores in stable middle-income areas. Online channels respond more to advertising than offline channels. Factor models capture this heterogeneity naturally. TROP, by estimating the factor structure and learning unit-specific loadings, can accommodate complex co-movement patterns that violate additive fixed effects.

Short pre-treatment periods (a common constraint in fast-moving industries) benefit from TROP's regularisation. The nuclear norm penalty prevents overfitting when the pre-treatment sample is small relative to the number of factors. Cross-validation guards against selecting overly complex models. This makes TROP more stable than unregularised matrix completion in marketing panels with only five to ten pre-treatment periods.

Staggered adoption patterns extend naturally to TROP. For each cohort, estimate TROP using only not-yet-treated donors, compute cohort-time effects, and aggregate into event-time profiles. The factor structure captures common trends across cohorts, while the unit and time weights accommodate cohort-specific deviations. This mirrors the SDID approach for staggered designs (Section~\ref{sec:hybrid-multiple}) but adds flexibility through the low-rank component.

The primary limitation is interpretability. TROP's factor loadings are rotational artefacts (Chapter~\ref{ch:factor}) and do not have direct economic meanings. The unit weights, time weights, and factor structure combine in complex ways to produce the counterfactual. This makes it harder to explain to non-technical stakeholders than simpler methods. Good practice pairs TROP estimates with simpler benchmarks (SDID, SC, DID) and uses TROP primarily when the benchmarks disagree or when pre-treatment fit is poor. Presenting TROP as a robustness check (testing whether conclusions hold under a more flexible specification) is often more persuasive than presenting it as the primary estimator.

\subsection*{Diagnostics and Inference}

Diagnostic protocols for TROP extend those developed for SDID and ASCM, but recent work by \citet{almeida2025estimating} highlights the critical importance of tailoring inference to the heteroskedasticity structure of the data.

**Variance Estimation and Placebo Tests.**
Standard inference relies on placebo tests, but these implicitly estimate different variances. The \textbf{Unit Placebo (UP)} test (applying the method to control units in the treated period) assumes unit exchangeability. It remains valid if volatility varies over time (e.g., volatile recession quarters vs. stable growth quarters) but loses power if units have different noise levels (e.g., a stable large retailer vs. a noisy small shop). Conversely, the \textbf{Time Placebo (TP)} test (applying the method to the treated unit in pre-treatment periods) assumes time exchangeability. It handles unit heterogeneity well but fails if time periods vary in volatility.

\paragraph{The Conditional Variance Estimator.}
For marketing panels, which often feature both unit heterogeneity (diverse markets) and time volatility (seasonal shocks), \citet{almeida2025estimating} propose the Conditional (C) variance estimator. This method models the idiosyncratic variance as $\sigma^2_{it} = \exp(\nu_i + \xi_t)$, capturing both dimensions. The implementation proceeds as follows. First, compute residuals from the TROP estimator: $\hat{\varepsilon}_{it} = Y_{it} - \hat{Y}_{it}^{\text{TROP}}(0)$ for all untreated observations. Second, regress the log squared residuals on unit and time fixed effects: $\ln(\hat{\varepsilon}_{it}^2) = \gamma + \nu_i + \xi_t + \eta_{it}$. Third, construct the conditional variance for the treated $(i,t)$ cell as $\hat{\sigma}^{2,C}_{it} = \exp(1.27 + \hat{\gamma} + \hat{\nu}_i + \hat{\xi}_t)$, where the constant 1.27 is a bias correction for the log-normal distribution. This estimator consistently outperforms standard placebo tests in simulations with two-way heteroskedasticity, providing tighter confidence intervals without sacrificing validity.

**Routine Diagnostics.**
Beyond variance estimation, standard checks remain essential. Pre-treatment RMSPE should be compared across methods (SC, SDID, ASCM, TROP). If TROP reduces RMSPE by 20 per cent or more, the complexity is likely justified. The cross-validation parameters provide structural insight: $\hat{\lambda}_{nn} \to \infty$ implies the factor structure is negligible (TROP $\approx$ SDID); $\hat{\lambda}_{\text{time}} \to 0$ implies all history is equally informative. Finally, weight dispersion metrics should be reported; highly concentrated weights suggest overfitting to a few idiosyncratic donors or periods.

\subsection*{Marketing Applications Where TROP May Be Beneficial}

The TROP estimator is a recent methodological development. The paper by \citet{athey2025triply} is an arXiv preprint presented at the 2025 ASSA meetings. It has not yet undergone peer review, and at the time of writing, no publicly available software implementation exists. Standard R or Python packages do not yet exist, requiring custom implementation of the convex optimization routine. Practitioners should therefore approach TROP with appropriate caution. It represents a promising research direction rather than a battle-tested tool. The following scenarios illustrate where TROP's features (factor structure, data-driven tuning, triple robustness) align with common challenges in marketing panels. These are conceptual guides rather than prescriptive recommendations.

Consider a consumer packaged goods brand evaluating television advertising across 40 designated market areas over ten quarters. Sales in different DMAs co-move due to national macroeconomic conditions (recession, inflation), seasonal patterns (holidays, summer), and category-wide trends (health food growth, carbonated beverage decline). However, the strength of co-movement varies. Affluent suburban DMAs respond strongly to economic downturns. Industrial DMAs are more sensitive to unemployment. Competitive DMAs exhibit muted responses due to market saturation. SDID assumes that time effects are uniform after reweighting. This additive structure may misfit the data if DMAs load heterogeneously on national shocks. TROP's low-rank factor model could capture these heterogeneous loadings. Whether this theoretical advantage translates to practical gains in real marketing data remains an open question. The method's cross-validation procedure would signal whether the factor structure improves predictions. If cross-validated tuning selects a large nuclear norm penalty (effectively $\lambda_{nn} \to \infty$), TROP reduces to SDID, and the simpler method suffices.

A second scenario involves store-level loyalty programme rollouts where stores cluster geographically. A retailer pilots loyalty in 20 stores across five regions over eight quarters. Stores within regions co-move due to shared demographics, competitive environments, and weather patterns. Flagship stores in wealthy suburbs respond differently to promotional shocks than discount formats in rural areas. The factor structure could model regional clustering (three to five regional factors) combined with format-specific loadings. The unit weights would prioritise stores in similar regions and formats. Time weights would down-weight volatile holiday quarters if those periods are less informative for predicting post-treatment outcomes. Whether this added complexity improves estimates over SDID or ASCM depends on the data. TROP provides a framework to test this empirically. If pre-treatment RMSPE for TROP is only marginally lower than SDID (say, 5 per cent improvement), the additional complexity may not justify the loss of transparency.

A third scenario addresses digital attribution in environments with structural breaks. A brand allocates budget across search, display, and social advertising for 30 products over 24 months. Platform algorithm changes (iOS App Tracking Transparency in month 12, Google Privacy Sandbox in month 18) alter attribution patterns. Products in different categories (luxury versus mass-market) respond differently to these changes. The factor structure could model pre-break and post-break regimes as separate components. Cross-validation could focus on recent pre-treatment periods that reflect current platform dynamics by selecting high time-weight decay ($\lambda_{\text{time}}$). However, if the structural break is severe, the factor model estimated on pre-break data may not extrapolate to post-break periods regardless of the method's flexibility. TROP's stability assumption (the factor structure holds in both pre- and post-treatment periods) would fail. In such cases, the analyst might restrict estimation to post-break control observations only, sacrificing sample size for relevance.

These scenarios share common features. Outcomes co-move due to common shocks, but units differ in their sensitivity to those shocks. The sample size is moderate (20 to 50 units, 10 to 30 periods), providing sufficient data to estimate a low-rank model without overfitting. Simpler methods (SC, SDID, ASCM) may achieve poor pre-treatment fit due to unmodelled interactive effects. TROP's theoretical properties suggest it could help in these settings. However, theory and practice often diverge. The method's performance in real marketing applications, with measurement error, strategic behaviour, and platform-specific confounds, remains to be established. Good practice would estimate SC, SDID, ASCM, and TROP in parallel, compare their pre-treatment fit and post-treatment estimates, and assess whether TROP's gains justify its complexity. If estimates converge across methods, conclusions are robust, and the simpler method is preferable. If estimates diverge substantially, TROP's diagnostics (cross-validated tuning parameters, factor interpretations, weight dispersion) can help diagnose whether the factor structure is genuine or an artefact of overfitting.

The absence of peer review and software implementation limits immediate adoption. Practitioners interested in TROP should monitor the literature for updates. If the paper is published in a peer-reviewed journal and software becomes available, the method merits serious consideration in settings where interactive fixed effects are plausible and where simpler methods achieve poor fit. Until then, TROP serves as a conceptual benchmark. It clarifies what triple robustness means in the panel context. It unifies SC, SDID, and matrix completion into a common framework. It provides a lens for understanding when and why these methods may fail. These contributions are valuable even if TROP itself does not become a workhorse estimator in applied marketing research.

\subsection*{Summary and Positioning in the Hybrid Methods Hierarchy}

The Triply RObust Panel estimator represents a recent development in hybrid methods for panel causal inference. It integrates unit weights, time weights, and factor structure into a unified framework with data-driven tuning via cross-validation. The method achieves triple robustness within a factor model framework, providing insurance against partial model failures through a multiplicative bias structure. Semi-synthetic benchmarks in \citet{athey2025triply} show substantial performance gains over existing methods in settings where interactive fixed effects are present and where unit and time heterogeneity are both relevant. Whether these gains extend to real marketing applications with measurement error, strategic behaviour, and platform-specific confounds remains an open empirical question.

TROP is most valuable conceptually when the analyst faces uncertainty about which identification mechanism (weighting, differencing, or factor modelling) is most appropriate, when interactive fixed effects are plausible, and when the sample size is sufficient to estimate a low-rank model. In such settings, TROP's flexibility and adaptive learning could provide credible counterfactuals without committing to a single identification strategy. The method should be used alongside simpler benchmarks (SDID, SC, ASCM) and should be justified by diagnostics showing that it achieves better pre-treatment fit or greater robustness to specification choices. Until peer-reviewed publication and software implementation emerge, practitioners should treat TROP as a promising research direction rather than a mature tool.

The integration of TROP into the methodological landscape completes the hierarchy of hybrid methods developed in this chapter. Standard synthetic control provides transparent weighting when the treated unit lies within the donor convex hull. Augmented synthetic control adds regression adjustment when the treated unit is near but not within the hull. Ridge and balancing synthetic control stabilise weights when the donor pool is large or the pre-treatment period is short. Synthetic difference-in-differences incorporates time weights when parallel trends holds after reweighting. Triply robust panel estimation combines all three components, learning their relative importance from the data. Together, these methods provide flexible, robust, and interpretable frameworks for causal inference in complex marketing panels. TROP extends this hierarchy by adding factor structure, but its practical utility awaits empirical validation in real marketing settings.
