
\section{Motivation and Setup}
\label{sec:dml-motivation}

Modern marketing panels confront practitioners with high-dimensional covariates, complex nonlinear relationships, and heterogeneous treatment effects that vary across units and over time. A retailer analysing a promotional campaign observes hundreds of store characteristics and dozens of time-varying market conditions. Traditional parametric methods restrict the functional form severely, potentially misspecifying the relationship between controls and outcomes. Machine learning offers a natural solution: data-driven algorithms that adapt to high-dimensional covariate spaces without imposing restrictive functional forms.

The challenge is preserving valid causal inference when using ML methods. Causal identification in panels relies on the assumptions articulated in Chapter~\ref{ch:frameworks}. ML methods, optimised for prediction accuracy rather than causal identification, do not automatically respect these assumptions. If an analyst naïvely regresses outcomes on treatment and high-dimensional covariates using a black-box ML algorithm, the resulting estimate may be biased due to overfitting, regularisation bias, or failure to account for confounding.

Double/debiased machine learning (DML) resolves this tension by combining flexible ML estimation of nuisance functions with principled causal inference procedures. The key insights are orthogonalisation and sample splitting. Orthogonalisation constructs score functions that are first-order insensitive to small errors in nuisance estimates, ensuring that regularisation bias does not contaminate the treatment effect estimate. Sample splitting (cross-fitting) trains nuisance models on one subset of the data and evaluates them on a disjoint subset, preventing overfitting and enabling standard asymptotic theory. Together, these techniques enable analysts to enjoy the flexibility of ML for nuisance estimation while retaining the credibility of design-based causal inference.

DML does not relax the identification assumptions from Chapter~\ref{ch:frameworks}. It provides a principled way to estimate nuisance functions flexibly while ensuring that treatment effect estimates remain unbiased and inference remains valid. The identification assumptions remain paramount. DML enables richer conditioning sets and more flexible functional forms, extending the design-based toolkit \citep{angrist2010credibility} to settings with high-dimensional controls and heterogeneous effects.

\subsection*{Relation to Factor and Hybrid Methods}

Factor models (Chapter~\ref{ch:factor}) estimate low-rank structures that capture time-varying common shocks, enabling identification when parallel trends fails. DML complements factor models by using ML to estimate factor loadings or residual outcome models after removing factor structure. Hybrid methods such as augmented synthetic control and synthetic difference-in-differences combine weighting with regression adjustment. DML extends these by using ML for the regression component, enabling richer covariate spaces and more flexible outcome models.

\subsection*{Marketing Motivation}

Consider a retailer launching a loyalty programme in 200 stores over six quarters (staggered adoption), with 50 pre-treatment covariates per store. The goal is to estimate the ATT at each lag and assess whether effects vary across store types.

A naïve two-way fixed effects regression provides limited flexibility. Synthetic control methods struggle when treated units are numerous and adoption is staggered. DML provides a middle ground: it estimates nuisance functions using ML, constructs orthogonal scores that are insensitive to nuisance estimation error, and aggregates cohort-time effects into event-time profiles. The result is an estimator that is flexible, robust, and transparent.

\subsection*{Chapter Roadmap}

We begin with Neyman-orthogonal scores (Section~\ref{sec:dml-orthogonal}) and cross-fitting under panel dependence (Section~\ref{sec:dml-crossfit}). We then develop DML estimators for average effects, staggered designs, and dose-response functions (Sections~\ref{sec:dml-estimators} and~\ref{sec:dml-dose-response}), before turning to heterogeneous treatment effects (Section~\ref{sec:dml-hte}) and policy learning (Section~\ref{sec:dml-policy}). The chapter concludes with identification assumptions (Section~\ref{sec:dml-assumptions}), tuning guidance (Section~\ref{sec:dml-tuning}), diagnostics (Section~\ref{sec:dml-diagnostics}), inference (Section~\ref{sec:dml-inference}), marketing applications (Section~\ref{sec:dml-marketing}), and a workflow checklist (Section~\ref{sec:dml-workflow}).
